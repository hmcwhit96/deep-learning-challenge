{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  import data\n",
    "apps_df = pd.read_csv('Resources\\charity_data.csv')\n",
    "apps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "apps_df.drop(['EIN', 'NAME'], axis=1, inplace=True)\n",
    "apps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apps_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_counts = apps_df['APPLICATION_TYPE'].value_counts()\n",
    "app_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "Other     2266\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raised the cutoff value to reduce number of application types \n",
    "app_types_to_replace = list(app_counts[app_counts < 1000].index)\n",
    "\n",
    "for app in app_types_to_replace:\n",
    "    apps_df['APPLICATION_TYPE'] = apps_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "apps_df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C1800       15\n",
       "C6000       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1238       10\n",
       "C1278       10\n",
       "C1237        9\n",
       "C1235        9\n",
       "C7210        7\n",
       "C2400        6\n",
       "C4100        6\n",
       "C1720        6\n",
       "C1600        5\n",
       "C1257        5\n",
       "C1260        3\n",
       "C0           3\n",
       "C2710        3\n",
       "C1234        2\n",
       "C1246        2\n",
       "C1256        2\n",
       "C3200        2\n",
       "C1267        2\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = apps_df['CLASSIFICATION'].value_counts()\n",
    "class_counts[class_counts > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_replace = list(class_counts[class_counts < 1000].index)\n",
    "\n",
    "for cl in class_to_replace:\n",
    "    apps_df['CLASSIFICATION'] = apps_df['CLASSIFICATION'].replace(cl,\"Other\")\n",
    "\n",
    "apps_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                       1   \n",
       "1       1   108590              1                       0   \n",
       "2       1     5000              0                       0   \n",
       "3       1     6692              1                       0   \n",
       "4       1   142590              1                       0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                     0                    0                    0   \n",
       "1                     0                    1                    0   \n",
       "2                     0                    0                    0   \n",
       "3                     0                    1                    0   \n",
       "4                     0                    1                    0   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  AFFILIATION_CompanySponsored  \\\n",
       "0                    0                    0                             0   \n",
       "1                    0                    0                             0   \n",
       "2                    1                    0                             1   \n",
       "3                    0                    0                             1   \n",
       "4                    0                    0                             0   \n",
       "\n",
       "   ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0  ...                  0                       0                         0   \n",
       "1  ...                  1                       0                         0   \n",
       "2  ...                  0                       0                         0   \n",
       "3  ...                  0                       1                         0   \n",
       "4  ...                  0                       0                         1   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                   0                 0                       0   \n",
       "1                   0                 0                       0   \n",
       "2                   0                 0                       0   \n",
       "3                   0                 0                       0   \n",
       "4                   0                 0                       0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                0                  0                         1   \n",
       "1                0                  0                         1   \n",
       "2                0                  0                         1   \n",
       "3                0                  0                         1   \n",
       "4                0                  0                         1   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apps_dummies_df = pd.get_dummies(apps_df)\n",
    "apps_dummies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into features and targets\n",
    "X = apps_dummies_df.drop(['IS_SUCCESSFUL'], axis=1)\n",
    "y = apps_dummies_df['IS_SUCCESSFUL']\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scaler and fit to the training data, then scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler_train = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler_train.transform(X_train)\n",
    "X_test_scaled = X_scaler_train.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization: Compile, Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 100)               4100      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 60)                6060      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,160\n",
      "Trainable params: 10,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the neural network model\n",
    "feature_count = len(X_train_scaled[0])\n",
    "# adjust the number of nodes in the hidden layers\n",
    "node_count = int(feature_count * 2.5)\n",
    "node_count_2 = int(feature_count * 1.5)\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count, activation='relu', input_shape=(feature_count,)))\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count_2, activation='relu'))\n",
    "\n",
    "# check structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increased the number of parameters from 7731 to 10160."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model_fit = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of parameters drastically lowered the model's accuracy, we need to try something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T3       27037\n",
      "Other     2266\n",
      "T4        1542\n",
      "T6        1216\n",
      "T5        1173\n",
      "T19       1065\n",
      "Name: APPLICATION_TYPE, dtype: int64\n",
      "Independent         18480\n",
      "CompanySponsored    15705\n",
      "Family/Parent          64\n",
      "National               33\n",
      "Regional               13\n",
      "Other                   4\n",
      "Name: AFFILIATION, dtype: int64\n",
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "Other     2261\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "Name: CLASSIFICATION, dtype: int64\n",
      "Preservation     28095\n",
      "ProductDev        5671\n",
      "CommunityServ      384\n",
      "Heathcare          146\n",
      "Other                3\n",
      "Name: USE_CASE, dtype: int64\n",
      "Trust           23515\n",
      "Association     10255\n",
      "Co-operative      486\n",
      "Corporation        43\n",
      "Name: ORGANIZATION, dtype: int64\n",
      "1    34294\n",
      "0        5\n",
      "Name: STATUS, dtype: int64\n",
      "0                24388\n",
      "25000-99999       3747\n",
      "100000-499999     3374\n",
      "1M-5M              955\n",
      "1-9999             728\n",
      "10000-24999        543\n",
      "10M-50M            240\n",
      "5M-10M             185\n",
      "50M+               139\n",
      "Name: INCOME_AMT, dtype: int64\n",
      "N    34272\n",
      "Y       27\n",
      "Name: SPECIAL_CONSIDERATIONS, dtype: int64\n",
      "5000       25398\n",
      "15583          3\n",
      "6725           3\n",
      "63981          3\n",
      "10478          3\n",
      "           ...  \n",
      "75598          1\n",
      "22336          1\n",
      "44863          1\n",
      "5928           1\n",
      "6948863        1\n",
      "Name: ASK_AMT, Length: 8747, dtype: int64\n",
      "1    18261\n",
      "0    16038\n",
      "Name: IS_SUCCESSFUL, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# examine the dataset to see if other features can be binned\n",
    "for col in apps_df.columns:\n",
    "    print(apps_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0            Other       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  IS_SUCCESSFUL  \n",
       "0   Association       1              0                      N              1  \n",
       "1  Co-operative       1         1-9999                      N              1  \n",
       "2   Association       1              0                      N              0  \n",
       "3         Trust       1    10000-24999                      N              1  \n",
       "4         Trust       1  100000-499999                      N              1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  drop the ask amount column because of how much it is skewed\n",
    "apps_df.drop(['ASK_AMT'], axis=1, inplace=True)\n",
    "apps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                24388\n",
       "25000-99999       3747\n",
       "100000-499999     3374\n",
       "1M-5M              955\n",
       "1-9999             728\n",
       "Other              564\n",
       "10000-24999        543\n",
       "Name: INCOME_AMT, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bin the income amount column\n",
    "income_counts = apps_df['INCOME_AMT'].value_counts()\n",
    "\n",
    "incomes_to_replace = ['5M-10M','10M-50M', '10M-50M', '50M+']\n",
    "\n",
    "for income in incomes_to_replace:\n",
    "    apps_df['INCOME_AMT'] = apps_df['INCOME_AMT'].replace(income,\"Other\")\n",
    "\n",
    "apps_df['INCOME_AMT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_Other</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T19  \\\n",
       "0       1              1                       1                     0   \n",
       "1       1              1                       0                     0   \n",
       "2       1              0                       0                     0   \n",
       "3       1              1                       0                     0   \n",
       "4       1              1                       0                     0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
       "0                    0                    0                    0   \n",
       "1                    1                    0                    0   \n",
       "2                    0                    0                    1   \n",
       "3                    1                    0                    0   \n",
       "4                    1                    0                    0   \n",
       "\n",
       "   APPLICATION_TYPE_T6  AFFILIATION_CompanySponsored  \\\n",
       "0                    0                             0   \n",
       "1                    0                             0   \n",
       "2                    0                             1   \n",
       "3                    0                             1   \n",
       "4                    0                             0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  ...  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
       "0                          0  ...                   0             1   \n",
       "1                          0  ...                   0             0   \n",
       "2                          0  ...                   0             1   \n",
       "3                          0  ...                   1             0   \n",
       "4                          0  ...                   1             0   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                  0                       0                         0   \n",
       "1                  1                       0                         0   \n",
       "2                  0                       0                         0   \n",
       "3                  0                       1                         0   \n",
       "4                  0                       0                         1   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_Other  \\\n",
       "0                 0                       0                 0   \n",
       "1                 0                       0                 0   \n",
       "2                 0                       0                 0   \n",
       "3                 0                       0                 0   \n",
       "4                 0                       0                 0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                         1                         0  \n",
       "1                         1                         0  \n",
       "2                         1                         0  \n",
       "3                         1                         0  \n",
       "4                         1                         0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_dummies_df = pd.get_dummies(apps_df)\n",
    "optimize_dummies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into features and targets\n",
    "X = optimize_dummies_df.drop(['IS_SUCCESSFUL'], axis=1)\n",
    "y = optimize_dummies_df['IS_SUCCESSFUL']\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 90)                3690      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 45)                4095      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 46        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,831\n",
      "Trainable params: 7,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the neural network model\n",
    "feature_count = len(X_train_scaled[0])\n",
    "node_count = 90\n",
    "node_count_2 = 45\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count, activation='relu', input_shape=(feature_count,)))\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count_2, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# check structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increased the number of neurons per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5712 - accuracy: 0.7237\n",
      "Epoch 2/100\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7292\n",
      "Epoch 3/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5551 - accuracy: 0.7312\n",
      "Epoch 4/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5532 - accuracy: 0.7314\n",
      "Epoch 5/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5528 - accuracy: 0.7329\n",
      "Epoch 6/100\n",
      "858/858 [==============================] - 1s 873us/step - loss: 0.5510 - accuracy: 0.7328\n",
      "Epoch 7/100\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5500 - accuracy: 0.7334\n",
      "Epoch 8/100\n",
      "858/858 [==============================] - 1s 894us/step - loss: 0.5496 - accuracy: 0.7337\n",
      "Epoch 9/100\n",
      "858/858 [==============================] - 1s 925us/step - loss: 0.5490 - accuracy: 0.7325\n",
      "Epoch 10/100\n",
      "858/858 [==============================] - 1s 937us/step - loss: 0.5484 - accuracy: 0.7340\n",
      "Epoch 11/100\n",
      "858/858 [==============================] - 1s 923us/step - loss: 0.5482 - accuracy: 0.7345\n",
      "Epoch 12/100\n",
      "858/858 [==============================] - 1s 938us/step - loss: 0.5472 - accuracy: 0.7349\n",
      "Epoch 13/100\n",
      "858/858 [==============================] - 1s 946us/step - loss: 0.5475 - accuracy: 0.7348\n",
      "Epoch 14/100\n",
      "858/858 [==============================] - 1s 951us/step - loss: 0.5468 - accuracy: 0.7347\n",
      "Epoch 15/100\n",
      "858/858 [==============================] - 1s 975us/step - loss: 0.5464 - accuracy: 0.7348\n",
      "Epoch 16/100\n",
      "858/858 [==============================] - 1s 934us/step - loss: 0.5462 - accuracy: 0.7352\n",
      "Epoch 17/100\n",
      "858/858 [==============================] - 1s 937us/step - loss: 0.5461 - accuracy: 0.7346\n",
      "Epoch 18/100\n",
      "858/858 [==============================] - 1s 940us/step - loss: 0.5451 - accuracy: 0.7354\n",
      "Epoch 19/100\n",
      "858/858 [==============================] - 1s 944us/step - loss: 0.5456 - accuracy: 0.7351\n",
      "Epoch 20/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7367\n",
      "Epoch 21/100\n",
      "858/858 [==============================] - 1s 956us/step - loss: 0.5447 - accuracy: 0.7376\n",
      "Epoch 22/100\n",
      "858/858 [==============================] - 1s 950us/step - loss: 0.5448 - accuracy: 0.7362\n",
      "Epoch 23/100\n",
      "858/858 [==============================] - 1s 921us/step - loss: 0.5441 - accuracy: 0.7368\n",
      "Epoch 24/100\n",
      "858/858 [==============================] - 1s 946us/step - loss: 0.5441 - accuracy: 0.7368\n",
      "Epoch 25/100\n",
      "858/858 [==============================] - 1s 989us/step - loss: 0.5440 - accuracy: 0.7367\n",
      "Epoch 26/100\n",
      "858/858 [==============================] - 1s 933us/step - loss: 0.5435 - accuracy: 0.7362\n",
      "Epoch 27/100\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5437 - accuracy: 0.7375\n",
      "Epoch 28/100\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5431 - accuracy: 0.7370\n",
      "Epoch 29/100\n",
      "858/858 [==============================] - 1s 923us/step - loss: 0.5434 - accuracy: 0.7369\n",
      "Epoch 30/100\n",
      "858/858 [==============================] - 1s 923us/step - loss: 0.5434 - accuracy: 0.7380\n",
      "Epoch 31/100\n",
      "858/858 [==============================] - 1s 983us/step - loss: 0.5429 - accuracy: 0.7373\n",
      "Epoch 32/100\n",
      "858/858 [==============================] - 1s 981us/step - loss: 0.5430 - accuracy: 0.7379\n",
      "Epoch 33/100\n",
      "858/858 [==============================] - 1s 932us/step - loss: 0.5428 - accuracy: 0.7375\n",
      "Epoch 34/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5426 - accuracy: 0.7383\n",
      "Epoch 35/100\n",
      "858/858 [==============================] - 1s 957us/step - loss: 0.5421 - accuracy: 0.7371\n",
      "Epoch 36/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7376\n",
      "Epoch 37/100\n",
      "858/858 [==============================] - 1s 956us/step - loss: 0.5423 - accuracy: 0.7380\n",
      "Epoch 38/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7378\n",
      "Epoch 39/100\n",
      "858/858 [==============================] - 1s 929us/step - loss: 0.5419 - accuracy: 0.7381\n",
      "Epoch 40/100\n",
      "858/858 [==============================] - 1s 933us/step - loss: 0.5418 - accuracy: 0.7381\n",
      "Epoch 41/100\n",
      "858/858 [==============================] - 1s 909us/step - loss: 0.5416 - accuracy: 0.7385\n",
      "Epoch 42/100\n",
      "858/858 [==============================] - 1s 950us/step - loss: 0.5416 - accuracy: 0.7380\n",
      "Epoch 43/100\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5415 - accuracy: 0.7383\n",
      "Epoch 44/100\n",
      "858/858 [==============================] - 1s 942us/step - loss: 0.5413 - accuracy: 0.7383\n",
      "Epoch 45/100\n",
      "858/858 [==============================] - 1s 939us/step - loss: 0.5408 - accuracy: 0.7389\n",
      "Epoch 46/100\n",
      "858/858 [==============================] - 1s 924us/step - loss: 0.5411 - accuracy: 0.7388\n",
      "Epoch 47/100\n",
      "858/858 [==============================] - 1s 955us/step - loss: 0.5409 - accuracy: 0.7386\n",
      "Epoch 48/100\n",
      "858/858 [==============================] - 1s 994us/step - loss: 0.5414 - accuracy: 0.7390\n",
      "Epoch 49/100\n",
      "858/858 [==============================] - 1s 941us/step - loss: 0.5408 - accuracy: 0.7384\n",
      "Epoch 50/100\n",
      "858/858 [==============================] - 1s 925us/step - loss: 0.5408 - accuracy: 0.7388\n",
      "Epoch 51/100\n",
      "858/858 [==============================] - 1s 917us/step - loss: 0.5404 - accuracy: 0.7389\n",
      "Epoch 52/100\n",
      "858/858 [==============================] - 1s 959us/step - loss: 0.5411 - accuracy: 0.7382\n",
      "Epoch 53/100\n",
      "858/858 [==============================] - 1s 934us/step - loss: 0.5405 - accuracy: 0.7388\n",
      "Epoch 54/100\n",
      "858/858 [==============================] - 1s 936us/step - loss: 0.5406 - accuracy: 0.7387\n",
      "Epoch 55/100\n",
      "858/858 [==============================] - 1s 919us/step - loss: 0.5405 - accuracy: 0.7388\n",
      "Epoch 56/100\n",
      "858/858 [==============================] - 1s 936us/step - loss: 0.5405 - accuracy: 0.7382\n",
      "Epoch 57/100\n",
      "858/858 [==============================] - 1s 938us/step - loss: 0.5404 - accuracy: 0.7379\n",
      "Epoch 58/100\n",
      "858/858 [==============================] - 1s 927us/step - loss: 0.5403 - accuracy: 0.7395\n",
      "Epoch 59/100\n",
      "858/858 [==============================] - 1s 912us/step - loss: 0.5400 - accuracy: 0.7387\n",
      "Epoch 60/100\n",
      "858/858 [==============================] - 1s 926us/step - loss: 0.5399 - accuracy: 0.7389\n",
      "Epoch 61/100\n",
      "858/858 [==============================] - 1s 938us/step - loss: 0.5401 - accuracy: 0.7387\n",
      "Epoch 62/100\n",
      "858/858 [==============================] - 1s 932us/step - loss: 0.5395 - accuracy: 0.7390\n",
      "Epoch 63/100\n",
      "858/858 [==============================] - 1s 939us/step - loss: 0.5398 - accuracy: 0.7398\n",
      "Epoch 64/100\n",
      "858/858 [==============================] - 1s 925us/step - loss: 0.5399 - accuracy: 0.7393\n",
      "Epoch 65/100\n",
      "858/858 [==============================] - 1s 919us/step - loss: 0.5397 - accuracy: 0.7394\n",
      "Epoch 66/100\n",
      "858/858 [==============================] - 1s 917us/step - loss: 0.5393 - accuracy: 0.7391\n",
      "Epoch 67/100\n",
      "858/858 [==============================] - 1s 956us/step - loss: 0.5397 - accuracy: 0.7393\n",
      "Epoch 68/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5394 - accuracy: 0.7393\n",
      "Epoch 69/100\n",
      "858/858 [==============================] - 1s 952us/step - loss: 0.5397 - accuracy: 0.7391\n",
      "Epoch 70/100\n",
      "858/858 [==============================] - 1s 925us/step - loss: 0.5396 - accuracy: 0.7389\n",
      "Epoch 71/100\n",
      "858/858 [==============================] - 1s 931us/step - loss: 0.5392 - accuracy: 0.7389\n",
      "Epoch 72/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7390\n",
      "Epoch 73/100\n",
      "858/858 [==============================] - 1s 919us/step - loss: 0.5394 - accuracy: 0.7393\n",
      "Epoch 74/100\n",
      "858/858 [==============================] - 1s 936us/step - loss: 0.5390 - accuracy: 0.7396\n",
      "Epoch 75/100\n",
      "858/858 [==============================] - 1s 924us/step - loss: 0.5387 - accuracy: 0.7395\n",
      "Epoch 76/100\n",
      "858/858 [==============================] - 1s 926us/step - loss: 0.5393 - accuracy: 0.7394\n",
      "Epoch 77/100\n",
      "858/858 [==============================] - 1s 959us/step - loss: 0.5389 - accuracy: 0.7397\n",
      "Epoch 78/100\n",
      "858/858 [==============================] - 1s 930us/step - loss: 0.5387 - accuracy: 0.7397\n",
      "Epoch 79/100\n",
      "858/858 [==============================] - 1s 937us/step - loss: 0.5390 - accuracy: 0.7398\n",
      "Epoch 80/100\n",
      "858/858 [==============================] - 1s 971us/step - loss: 0.5387 - accuracy: 0.7397\n",
      "Epoch 81/100\n",
      "858/858 [==============================] - 1s 932us/step - loss: 0.5386 - accuracy: 0.7400\n",
      "Epoch 82/100\n",
      "858/858 [==============================] - 1s 951us/step - loss: 0.5389 - accuracy: 0.7395\n",
      "Epoch 83/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5390 - accuracy: 0.7396\n",
      "Epoch 84/100\n",
      "858/858 [==============================] - 1s 922us/step - loss: 0.5389 - accuracy: 0.7399\n",
      "Epoch 85/100\n",
      "858/858 [==============================] - 1s 956us/step - loss: 0.5388 - accuracy: 0.7398\n",
      "Epoch 86/100\n",
      "858/858 [==============================] - 1s 943us/step - loss: 0.5381 - accuracy: 0.7397\n",
      "Epoch 87/100\n",
      "858/858 [==============================] - 1s 940us/step - loss: 0.5383 - accuracy: 0.7396\n",
      "Epoch 88/100\n",
      "858/858 [==============================] - 1s 956us/step - loss: 0.5382 - accuracy: 0.73970s - loss: 0.5373 - accuracy\n",
      "Epoch 89/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.7395\n",
      "Epoch 90/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5395 - accuracy: 0.7395\n",
      "Epoch 91/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7400\n",
      "Epoch 92/100\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5383 - accuracy: 0.7402\n",
      "Epoch 93/100\n",
      "858/858 [==============================] - 1s 943us/step - loss: 0.5388 - accuracy: 0.7397\n",
      "Epoch 94/100\n",
      "858/858 [==============================] - 1s 940us/step - loss: 0.5384 - accuracy: 0.7403\n",
      "Epoch 95/100\n",
      "858/858 [==============================] - 1s 940us/step - loss: 0.5378 - accuracy: 0.7397\n",
      "Epoch 96/100\n",
      "858/858 [==============================] - 1s 954us/step - loss: 0.5376 - accuracy: 0.7397\n",
      "Epoch 97/100\n",
      "858/858 [==============================] - 1s 970us/step - loss: 0.5377 - accuracy: 0.7398\n",
      "Epoch 98/100\n",
      "858/858 [==============================] - 1s 975us/step - loss: 0.5381 - accuracy: 0.7402\n",
      "Epoch 99/100\n",
      "858/858 [==============================] - 1s 943us/step - loss: 0.5379 - accuracy: 0.7399\n",
      "Epoch 100/100\n",
      "858/858 [==============================] - 1s 921us/step - loss: 0.5378 - accuracy: 0.7398\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model_fit = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 0s - loss: 0.5692 - accuracy: 0.7273 - 202ms/epoch - 938us/step\n",
      "Model loss: 0.5692, accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "#  evaluate the model\n",
    "model_loss, model_acc = nn.evaluate(X_test_scaled, y_test,verbose=2)\n",
    "print(f'Model loss: {model_loss:.4f}, accuracy: {model_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning the income amount got nearly the same results as the original model, so next I will try to improve accuracy by adding another hidden layer to the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 100)               4100      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the new neural network model\n",
    "feature_count = len(X_train_scaled[0])\n",
    "node_count = 100\n",
    "node_count_2 = 50\n",
    "node_count_3 = 25\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count, activation='relu', input_shape=(feature_count,)))\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count_2, activation='relu'))\n",
    "# third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count_3, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5696 - accuracy: 0.7234: 0s - loss: 0.581\n",
      "Epoch 2/100\n",
      "858/858 [==============================] - 1s 993us/step - loss: 0.5566 - accuracy: 0.7295\n",
      "Epoch 3/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5549 - accuracy: 0.7311\n",
      "Epoch 4/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5526 - accuracy: 0.7320\n",
      "Epoch 5/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5511 - accuracy: 0.7326\n",
      "Epoch 6/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5508 - accuracy: 0.7326\n",
      "Epoch 7/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5500 - accuracy: 0.7337\n",
      "Epoch 8/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5499 - accuracy: 0.7321\n",
      "Epoch 9/100\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7336\n",
      "Epoch 10/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5482 - accuracy: 0.7352\n",
      "Epoch 11/100\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5482 - accuracy: 0.7349\n",
      "Epoch 12/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5472 - accuracy: 0.7345: 0s - loss: 0\n",
      "Epoch 13/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5478 - accuracy: 0.7344\n",
      "Epoch 14/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5467 - accuracy: 0.7349\n",
      "Epoch 15/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5464 - accuracy: 0.7345\n",
      "Epoch 16/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.7348: 0s - loss: 0.5464 - accuracy: \n",
      "Epoch 17/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5461 - accuracy: 0.7360\n",
      "Epoch 18/100\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7359\n",
      "Epoch 19/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5454 - accuracy: 0.7368\n",
      "Epoch 20/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5445 - accuracy: 0.7356: 1s - loss: 0.5431 - accuracy: \n",
      "Epoch 21/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7362\n",
      "Epoch 22/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7354\n",
      "Epoch 23/100\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5443 - accuracy: 0.7363: 1s\n",
      "Epoch 24/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7372\n",
      "Epoch 25/100\n",
      "858/858 [==============================] - 1s 962us/step - loss: 0.5439 - accuracy: 0.7370\n",
      "Epoch 26/100\n",
      "858/858 [==============================] - 1s 965us/step - loss: 0.5435 - accuracy: 0.7366\n",
      "Epoch 27/100\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7374: 0s - loss: 0.539 - E\n",
      "Epoch 28/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.7367\n",
      "Epoch 29/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7375\n",
      "Epoch 30/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7377\n",
      "Epoch 31/100\n",
      "858/858 [==============================] - 1s 917us/step - loss: 0.5429 - accuracy: 0.7371\n",
      "Epoch 32/100\n",
      "858/858 [==============================] - 1s 934us/step - loss: 0.5421 - accuracy: 0.7379\n",
      "Epoch 33/100\n",
      "858/858 [==============================] - 1s 921us/step - loss: 0.5427 - accuracy: 0.7375\n",
      "Epoch 34/100\n",
      "858/858 [==============================] - 1s 956us/step - loss: 0.5421 - accuracy: 0.7371\n",
      "Epoch 35/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7379\n",
      "Epoch 36/100\n",
      "858/858 [==============================] - 1s 942us/step - loss: 0.5422 - accuracy: 0.7375\n",
      "Epoch 37/100\n",
      "858/858 [==============================] - 1s 908us/step - loss: 0.5420 - accuracy: 0.7381\n",
      "Epoch 38/100\n",
      "858/858 [==============================] - 1s 940us/step - loss: 0.5418 - accuracy: 0.7373\n",
      "Epoch 39/100\n",
      "858/858 [==============================] - 1s 929us/step - loss: 0.5416 - accuracy: 0.7380\n",
      "Epoch 40/100\n",
      "858/858 [==============================] - 1s 972us/step - loss: 0.5415 - accuracy: 0.7383\n",
      "Epoch 41/100\n",
      "858/858 [==============================] - 1s 944us/step - loss: 0.5410 - accuracy: 0.7384\n",
      "Epoch 42/100\n",
      "858/858 [==============================] - 1s 919us/step - loss: 0.5411 - accuracy: 0.7387\n",
      "Epoch 43/100\n",
      "858/858 [==============================] - 1s 939us/step - loss: 0.5411 - accuracy: 0.7385\n",
      "Epoch 44/100\n",
      "858/858 [==============================] - 1s 985us/step - loss: 0.5409 - accuracy: 0.7387\n",
      "Epoch 45/100\n",
      "858/858 [==============================] - 1s 979us/step - loss: 0.5411 - accuracy: 0.7385\n",
      "Epoch 46/100\n",
      "858/858 [==============================] - 1s 944us/step - loss: 0.5413 - accuracy: 0.7384\n",
      "Epoch 47/100\n",
      "858/858 [==============================] - 1s 926us/step - loss: 0.5404 - accuracy: 0.7380\n",
      "Epoch 48/100\n",
      "858/858 [==============================] - 1s 956us/step - loss: 0.5405 - accuracy: 0.7387\n",
      "Epoch 49/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5407 - accuracy: 0.7383\n",
      "Epoch 50/100\n",
      "858/858 [==============================] - 1s 923us/step - loss: 0.5405 - accuracy: 0.7388\n",
      "Epoch 51/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5406 - accuracy: 0.7385\n",
      "Epoch 52/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5406 - accuracy: 0.7385\n",
      "Epoch 53/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7391\n",
      "Epoch 54/100\n",
      "858/858 [==============================] - 1s 975us/step - loss: 0.5397 - accuracy: 0.7390\n",
      "Epoch 55/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.7387\n",
      "Epoch 56/100\n",
      "858/858 [==============================] - 1s 986us/step - loss: 0.5401 - accuracy: 0.7383\n",
      "Epoch 57/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5397 - accuracy: 0.7390: 0s -\n",
      "Epoch 58/100\n",
      "858/858 [==============================] - 1s 985us/step - loss: 0.5398 - accuracy: 0.7393\n",
      "Epoch 59/100\n",
      "858/858 [==============================] - 1s 975us/step - loss: 0.5398 - accuracy: 0.7387\n",
      "Epoch 60/100\n",
      "858/858 [==============================] - 1s 993us/step - loss: 0.5394 - accuracy: 0.7387\n",
      "Epoch 61/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7389\n",
      "Epoch 62/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7391\n",
      "Epoch 63/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5390 - accuracy: 0.7392\n",
      "Epoch 64/100\n",
      "858/858 [==============================] - 1s 939us/step - loss: 0.5390 - accuracy: 0.7389\n",
      "Epoch 65/100\n",
      "858/858 [==============================] - 1s 955us/step - loss: 0.5392 - accuracy: 0.7392\n",
      "Epoch 66/100\n",
      "858/858 [==============================] - 1s 955us/step - loss: 0.5387 - accuracy: 0.7395\n",
      "Epoch 67/100\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7395\n",
      "Epoch 68/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7395\n",
      "Epoch 69/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7396\n",
      "Epoch 70/100\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7392\n",
      "Epoch 71/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7400\n",
      "Epoch 72/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7392\n",
      "Epoch 73/100\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7394\n",
      "Epoch 74/100\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7394\n",
      "Epoch 75/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7393\n",
      "Epoch 76/100\n",
      "858/858 [==============================] - 1s 977us/step - loss: 0.5382 - accuracy: 0.7398\n",
      "Epoch 77/100\n",
      "858/858 [==============================] - 1s 941us/step - loss: 0.5382 - accuracy: 0.7395\n",
      "Epoch 78/100\n",
      "858/858 [==============================] - 1s 966us/step - loss: 0.5381 - accuracy: 0.7396\n",
      "Epoch 79/100\n",
      "858/858 [==============================] - 1s 947us/step - loss: 0.5380 - accuracy: 0.7394\n",
      "Epoch 80/100\n",
      "858/858 [==============================] - 1s 972us/step - loss: 0.5378 - accuracy: 0.7391\n",
      "Epoch 81/100\n",
      "858/858 [==============================] - 1s 989us/step - loss: 0.5384 - accuracy: 0.7402\n",
      "Epoch 82/100\n",
      "858/858 [==============================] - 1s 938us/step - loss: 0.5381 - accuracy: 0.7398\n",
      "Epoch 83/100\n",
      "858/858 [==============================] - 1s 985us/step - loss: 0.5377 - accuracy: 0.7402\n",
      "Epoch 84/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7397\n",
      "Epoch 85/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7399\n",
      "Epoch 86/100\n",
      "858/858 [==============================] - 1s 961us/step - loss: 0.5375 - accuracy: 0.7401\n",
      "Epoch 87/100\n",
      "858/858 [==============================] - 1s 920us/step - loss: 0.5378 - accuracy: 0.7396\n",
      "Epoch 88/100\n",
      "858/858 [==============================] - 1s 940us/step - loss: 0.5374 - accuracy: 0.7405\n",
      "Epoch 89/100\n",
      "858/858 [==============================] - 1s 939us/step - loss: 0.5375 - accuracy: 0.7396\n",
      "Epoch 90/100\n",
      "858/858 [==============================] - 1s 939us/step - loss: 0.5371 - accuracy: 0.7403\n",
      "Epoch 91/100\n",
      "858/858 [==============================] - 1s 926us/step - loss: 0.5375 - accuracy: 0.7397\n",
      "Epoch 92/100\n",
      "858/858 [==============================] - 1s 916us/step - loss: 0.5373 - accuracy: 0.7393\n",
      "Epoch 93/100\n",
      "858/858 [==============================] - 1s 921us/step - loss: 0.5373 - accuracy: 0.7397\n",
      "Epoch 94/100\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5370 - accuracy: 0.7403\n",
      "Epoch 95/100\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5377 - accuracy: 0.7400\n",
      "Epoch 96/100\n",
      "858/858 [==============================] - 1s 934us/step - loss: 0.5371 - accuracy: 0.7399\n",
      "Epoch 97/100\n",
      "858/858 [==============================] - 1s 920us/step - loss: 0.5373 - accuracy: 0.7398\n",
      "Epoch 98/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7397\n",
      "Epoch 99/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7399\n",
      "Epoch 100/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7394\n"
     ]
    }
   ],
   "source": [
    "#  train the model\n",
    "model_fit = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA4qElEQVR4nO3deXxU1fn48c+TnSRACAlLSAgBwg5hExBxRVpRVLRVcati1VqxtrYuYK1Va1v7/bV115ZadwUVN0SUsimobGELECBhJyxJ2ALZl3l+f8xNmGQSMkBCSPK8X6+8Mvfcc+89NwPzzFnuOaKqGGOMMZ78GroAxhhjzj4WHIwxxnix4GCMMcaLBQdjjDFeLDgYY4zxEtDQBagLUVFR2qVLl4YuhjHGNCorV648oKrR1e1rEsGhS5cuJCcnN3QxjDGmURGRnTXts2YlY4wxXiw4GGOM8WLBwRhjjJcm0edQnZKSEjIyMigsLGzoojRKISEhxMbGEhgY2NBFMcY0gCYbHDIyMmjZsiVdunRBRBq6OI2KqnLw4EEyMjJISEho6OIYYxpAk21WKiwspG3bthYYToGI0LZtW6t1GdOMNdngAFhgOA32tzOmeWvSwcEYY+rK4vRsNu8/1tDFOGMsOBhjTC2KS13c885K/jhzfUMX5Yyx4NAElJaWNnQRjGnSVuw4RF5xGck7DnO0sKTSvtcWb+Ofc9N8PldKxhHueWclB3OL6rqYdcqCQz0bP348Q4YMoW/fvkydOhWAr7/+msGDB5OUlMTo0aMByM3NZeLEifTv358BAwbw8ccfAxAeHl5xrhkzZnD77bcDcPvtt3PPPfcwfPhwHn74YZYvX865557LoEGDGDlyJJs3bwagrKyMBx98kH79+jFgwABefPFFFixYwPjx4yvOO3fuXK655poz8NcwpmEVlpSd0nELNmUBUOpSvks/UJFeVFrGC/PTeXnhFvYcKfDpXM/OTePrDfuZ9P4qSspcp1SeM8GnoawichnwPOAPvKaqz1TZ/yxwsbMZCrRT1QiP/a2AVOAzVb3PSRsCvAm0AGYDv1ZVFZFI4AOgC7ADuF5VD5/a7bk9+cUGUvcePZ1TeOkT04o/Xtm31nyvv/46kZGRFBQUcM4553D11Vdz1113sWjRIhISEjh06BAAf/rTn2jdujXr1q0D4PDh2m85IyODH374AX9/f44ePcrixYsJCAhg3rx5PProo3z88cdMnTqVHTt2sGbNGgICAjh06BBt2rTh3nvvJTs7m+joaN544w3uuOOO0/uDGHOW2H4gj6mLtvL7K/oQHnz8I25uaiaT3l/FCxMGcVm/Did1zoWbshjZrS0b9h5lwaYsLu/fEYBFaQc4Wuiuub+7dCePXNbrhOfZfSifb9KyGdQ5gqXbDvH0rFSevLrfSd7hmVFrzUFE/IGXgbFAH+BGEenjmUdVH1DVgao6EHgR+KTKaf4ELKqS9ipwF5Do/FzmpE8G5qtqIjDf2W60XnjhBZKSkhgxYgS7d+9m6tSpXHDBBRXPD0RGRgIwb948Jk2aVHFcmzZtaj33ddddh7+/PwA5OTlcd9119OvXjwceeIANGzZUnPcXv/gFAQEBFdcTEW699Vbeffddjhw5wpIlSxg7dmyd3rcxDeWj5N1MW76bxz873j9wJL+YKZ+so7jUxRMzN5BXVH1TbErGESZMXcKcDfsr0nYcyGPbgTzG9GnPBT2i+WZzFi6XAjBz7V7ahAZyae92TFu+q9aayQcrdiPASzcN5s5RCby1ZCcfrth9+jddD3ypOQwDtqjqNgARmQ5cjbsmUJ0bgT+Wbzg1hPbA18BQJ60j0EpVlzrbbwPjga+cc1/kHP4W8A3wiO+35M2Xb/j14ZtvvmHevHksWbKE0NBQLrroIgYOHMimTZt8PofnkNKqzx2EhYVVvP7DH/7AxRdfzKeffsqOHTu46KKLTnjeiRMncuWVVxISEsJ1111XETyMqQtZxwq5/Pnv+Mf1SVzYo9oZoevNkm0HCfQXPlm9h1GJUVw7OJYnv0jlSH4xfxrfjz98tp4X5qcz5fLeFceUlLl4acEWXlq4hTKXsutgPhf1jCY4wJ+Fm91NShf3bEdEaCBfrN3L+r05dG8XzrzUTK4Z3ImrkmKYt3EpM9fs5fpz4qotV0mZi+krdnNxz3Z0imjB5LG92Jx5jEc/Xcf3Ww9wy4h4hsa3qXUY+ZH8Ylq3CKz34ea+9Dl0AjxDW4aT5kVE4oEEYIGz7Qf8A3iwmnNm1HDO9qq6z3m9H3dgqe5ad4tIsogkZ2dn+3AbZ15OTg5t2rQhNDSUTZs2sXTpUgoLC1m0aBHbt28HqGhWGjNmDC+//HLFseXNSu3bt2fjxo24XC4+/fTTE16rUyf3n/DNN9+sSB8zZgz//ve/Kzqty68XExNDTEwMTz/9NBMnTqy7mzYGmJ2yjwO5RXyUfGa/FecVlZKSkcMdoxIYlhDJY5+t57XF2/h09R4mXdydW0fEc/3QWP773XbSMt3DUlfsOMQ1r3zP8/PTuSophlduHszenELeX7YLcPc3dI0Ko0tUGBckRiPiTpubmklBSRlXJcUwPCGSXh1a8sYPO1DVass2NzWTA7lF3DyiMwAB/n68dNNgbhkRz4KNWVz3ryWMfX4x7yzdSW4NNZtZKXsZ+vQ8npuXXg9/vcrqukN6AjBDVcvrVvcCs1U14wTH1Ejdf+Vq/9KqOlVVh6rq0OjoM/vNxFeXXXYZpaWl9O7dm8mTJzNixAiio6OZOnUq1157LUlJSdxwww0APPbYYxw+fJh+/fqRlJTEwoULAXjmmWcYN24cI0eOpGPHjjVe6+GHH2bKlCkMGjSo0uilO++8k86dOzNgwACSkpJ4//33K/bdfPPNxMXF0bt37+pOacwpm73O3SyzcFPWKXUC//Hz9fzuw7WUnmSHbfLOw5S5lPO6RfHcDQMJ9Pfj6S830qtDSyZd3B2AyWN7Ex4SwOSPU7j77WSu+9cSso8V8erNg3n2hoGM7deBEV0jeXnhFg7kFrFs2yEu7tUOgLbhwQyMi2Dhpiy+WLuPDq1CGNbF3VR7+8gubNx3lOXbD1VbtveW7aRTRAsu7NGuIq11i0CeuKovSx8dzV+v7Y+fCH/4bD3D/zyPxz5bx6b9x/tKZ6zM4P5pq/ET4T+Lt3Ggvkc7qeoJf4BzgTke21OAKTXkXQ2M9Nh+D9iFu2P5AHAUeAboCGzyyHcj8G/n9Wago/O6I7C5tjIOGTJEq0pNTfVKM5VNmjRJX3vttRr329/QnIrMnALtMnmWXvvK9xr/yCydv3H/SR2/dOsBjX9klsY/Mksf/HCNulwun4/96+yN2m3Kl5pXVKKqqnM37NdRf5uv6zKOVMr3/rKdGv/ILO37+Nf64vy0ivzlkncc1PhHZul1r/6g8Y/M0u/Ssyv2PT8vTeMfmaXdH/1S//TFhor0/KJSTXpyjt751gqvcm3LztX4R2bpi/PTTlh+l8ulq3Ye0gc+WK2Jv5+t8Y/M0p+++r0+PWuDxj8yS2/6zxJdl3FEu075Up+cueGE5/IFkKw1fK76UnNYASSKSIKIBOGuHcysmklEegFtgCUegedmVe2sql1wNy29raqT1d1sdFRERoi74exnwOfOYTOB25zXt3mkmzo0ZMgQUlJSuOWWWxq6KKYRO1ZYwrzUTMpcxyv4X63fjyo8dXVfwoMDmLM+0+fzuVzK019uJKZ1CL+8qBsfrczgb1+7h2WnZBxh8scpPDxjLTn5JdUev3TbQZLiIggNcvehXdqnPYsfvoR+nVpXynfD0Dj+dcsQvnnoIu67JLEif7kh8ZFc0qsdy3ccIizIn3O6RFbsu8SpRZSUKVcNjKlIbxHkzx3nJTA3NZMv1u6tdE9//nIjAX7C9UOr748oJyIM6tyGf14/kGVTRvP7y3uTdayI/yzeziW92vHf286hX6fW/GRwJ95dupO9Pg6fPRW19kKqaqmI3AfMwT2U9XVV3SAiT+GOOuWBYgIw3YlGvriX40NZv3J+wF2z+FBEfg7sBK739WaM71auXNnQRTCNWEmZi2nLd/H8vHQO5hXz8GU9ufcid7PN7HX7SGwXTt+Y1lzSqx3zNrqDh79f7R2on63Zw7o9OTx3w0CuHhjDscIS/vXtVv6Xup9t2Xm0CPSn1OVi+fZDvHbbOXRvd/w5oNyiUtbtyeGXF3ar9Tp+flLrcNbf/agHCzZlMSoxiqCA49+j+3RsRXTLYMKC/OlfJej88qJuLNycxaOfrGNgXARxkaE8Nz+deRsz+eOVfWjXKqTWspVrExbEXRd05eejEkjdd5SeHVoS6O8ux/2jE/ls9V5eXJDOX68d4PM5T4ZPQ1RUdTbuZxE80x6vsv1ELed4E3cwKN9OBrwG+KrqQWC0L+WqjaraBHKnyPcYb5qquamZTF++C1c1/xa2Zuex61A+wxMi6RPgx3Nz0xnTuz2tQwNZvuMQ91+SCMCP+3Zg5tq9JO84xPCubQFIzzxGhsc33q5RYcS3DaOguIz/+3ozA2Jbc1VSDCLCk1f1I7+4jNS9R3nyqr5cM7gTafuPcc+7K7nm5e954aZBXNzT/U1+xY5DlLmUEc51TlffmNa8eOMgendsVSndz094/oaBBAf6eX2+BPr78cKEQVz+wmJ+NW01Px+VwAvz07luSCy3j+xySuXw8xOvmk9sm1BuGt6Zd5bu5BcXdKNLVFgNR5+6Jjt+MSQkhIMHD9q03adAnfUcQkJ8/5Zjmg5V5cUFW/jn3DQ6RbSgbXiQV55OES3445V9uKRXOw7kFvOjZ7/lwRkpXDMwBlW4YoB78MRFPaMJCvDj6w37Gd61LZ+syuDBj9biqhJv4tuG0r5VCPuPFvLCjYPwc2oZ/n7CP68fWCnv0C6RfH7fKO56K5m7307m/btGcE6XSJY6Q1iHxNf+jJCvrkyKqTZ9ZPeoGo+JiwzlmWsHMOn9Vfxq2moGxkXw9DX96vxz6N6Lu/HBit38Z/E2/nxN/zo9NzTh4BAbG0tGRgZn6zDXs135SnDm7FRQXMbr32/n2sGd6Ni6RZ2e98EZa/kyZR/XDurEX67tT0ig/wmPiW4ZzJNX9+P+aatJ23+M7u3C6dG+JQBhwQGc3z2K/23IpHu7cB77bD0ju7Xldz/qiQAuVdbvOcri9GyWbD3IVUkxDEuIPOH1wB2cpt09gvEvf88v313JzPtGsXTrQQbGRdAi6MTlPROuGNCRFTu6MH9TJv++dQjBAXVfpnYtQ3hz4jkMiI2o83MDSFNoPhg6dKgmJyc3dDGMOSNyi0q5860VLN12iPEDY3huwqCTOn79nhymLd9F27AgHhjTo+IbbZlLuePNFSxKz2byZb24+4KuPn/bVVXueXclczZkcv/oRH47pkfFvg9X7Obhj1MAd2fuKzcPrjbguFyKyMmtJbIl6xjjX/6BuMhQNu8/yqSLu/O7H/X0+fj65nJpRS3obCQiK1V1aHX7mmzNwZiznapS6tKKTkZf5BSUcPsby0nJyGFIfBu+SNnHQ5f1olNE7bWHr9fv59+LtrJ61xEC/IRSp23nt86H6f99vYlv07L5yzX9uWl455O6FxHh6fHuWsaEKk8IX9qnPS1nBTAqMYrnJwyq1Lnr6VQ+RLu3a8lzNwzkrneSUYVz66i/oa6czYGhNhYcjGkgr3+/g7/M3siguAjOT4zm0j7t6BvTusb8BcVl3PzaUjbvP8bLNw2mf2xrLvi/hbzx3XYeG9enxuMO5xXzh8/XMytlH12jw3h8XB9+MjiWP89O5YUFW2gbHkzrFoH8e9E2bh0Rf9KBoVx0y2Cer6YWExkWxJJHRxMW5F8v/X+X9mnPlLG9eGfpTgbXYX9Dc2fNSsY0gJyCEi74v4V0aBVCcKAf6/bkoArP3pDENYOq7+v5KHk3D81I4dWbBzPWmRX019NXMy81kx+mjKZ1i0CvY75Ny+ahj9ZyOL+Y31zag19c0JUAp6ZSWubil++tYt7GTAL9/RgYF8F7dw4/qZqMadxO1Kxk/wqMqQerdx1m/saaH/767+Jt5BSU8I/rk5h53yhWPjaGc7u25aGPUiomeqvqo+QMukaFVRqff/cFXckrLquYB8jTp6szmPjGctqEBvHZpPOYdHH3isAA7rl9XrxxEMMTIunQKoRXbh5sgcFUsH8JxjhUldS9R096Pp+qCorLuPudlfz8rWQ+X7PHa//B3CL++912rujfsWL8emRYEFN/NoSeHVpy77urWLWr8noe27JzWb7jENcNjavUNNM3pjWjukfxxvfbKS49Xu73l+3itx+uZUTXtnw6aWSNzVUhgf68f+cI5v72AqLCg0/rvk3TYsHBNDuFJWV8ujqDrGPHp0A/mFvEL99dxeUvLOYX76z0ebK4p2elMnXR1kppby/ZQfaxInq0D+d3H67l27TKw6lf/WYrBSVlPOAxogegZUggb04cRrtWwdzx5gp2Hcyv2PfRygz8/YSfDPaeEPnuC7qSdayIn7z6A7/7cC1TPlnHo5+u46Ie0bx++zleU0NU5ecn9TLU0jRuFhxMs1JS5uLe91bxwAdrGfnXBUx6fxXvLNnBj59bxIJNWYwfGMP8TVnc+VYy+cUnXpt7W3Yur323nb/M3sRCZxnJo4UlvPrtVi7sEc2MX44ksX1L7nlnJQs3ZZGWeYyVOw/x9tKdXDs4ttLUD+WiWwbz9h3DKHMpv5q+mpIyF6VlLj5emcHFPaOrnX7h/MQofj06kZBAPxanZzNt+S7GDejIv28dWuszCsbUxEYrmWZDVZn88ToWbMrioR/35FBeMTNWZvBlyj56d2zFu3cm0atDK0YlRvPwjLXc9vpyJo/tRefIMKLCg7xG2kxbvosAP6FLVBgPfrSWr359Pu8t28WR/BIe/FFPWoUE8tYd5/DTV5cw8c0VFccF+gu/Hp1YYznj24bxt58M4N73VvH3/21meEIkWceKuK6GSdtEhAfG9KioiRSXumocLmqMr2y0kmk2/jp7I/9etI0HLu3Bry91fzgXlpSxbk8OSbERlT5QZ6Xs5TfT11Q8CxAeHMDjV/apmFWzsKSMEX+dz3ndonhgTCLjXvyOAZ0iSN13lPMTo3j1liEV5zqUV8zSbQcp/68WF9nCp6dap3yyjmnLd9EtOoycghKWTBltHcamTtlDcKZZKi1z8W1aNovTD7AoLZttB/L42bnx3D+6e0WekMDK0zGXGzcghiHxbdi47yg7D+Yzc+1eHv98PcO6RNIlKoyv1u/jSH4JNw3vTPd2LXniyr5M/mQdfkKlp4PB3dlcviD9yXh8XB+SdxwiPSuXu85PsMBgzigLDqZJKiwp4973VrFgUxYhgX6M6NqWiaMSuGlYZ58fxOrYukXFvEVj+3VkzLPf8vCMFKbfPYL3l+0iISqs4oncG86JY9uBPMKCAkh05hU6XS2C/HnppsH8ZfZGfnZulzo5pzG+smYl0yilZBzhYG5xxfKNnvKLS7n77ZV8v/UAfxzXhxuHd66T0TgfJu/m4Rkp3Dy8M+8t28XvL+/NXRd0Pe3zGtNQ7CE406S4XMoDH6zhvvdXeQ05PVZYwm2vL+eHrQf4x3VJ3H5eQp0N07xuSCwX9ojmvWW7CPL34ydDbNZa03RZcDCNzndbDrA1O4+84jKvZwj+OTeNVbuO8OKNg7l2cN1+eIsIf722Py1DAhiX1JHIMO91DoxpKiw4mAahqrz+3Xa2ZeeeMF9hSVml9YkB3vxhB1HhQbQJDWT2un2V8n6yag9j+3WoWGymrsVEtGD+by/kz+PrfnEVY84mFhxMg0jLzOWpWanc+96qStM+VHXza8u45pXvKSh2Nx9tP5DHgk1Z3DQ8nh/16cD8jVkVTUvzNmaSU1BS6yLup6tdq5CzYkEZY+qTBQdT76ob9DBnw34ANu0/xksLt1R7nPuJ4sOkZOTwyMcpqCpvL9lBgJ9wy/DOXD6gI7lFpSxympY+TM4gpnUI551gCUdjjG98Cg4icpmIbBaRLSIyuZr9z4rIGucnTUSOOOnxIrLKSd8gIvc46S098q8RkQMi8pyz73YRyfbYd2fd3a45kw7mFvHEzA30fvxrFqdX7hv4ev1+hsS34dpBnXhl4RbW78nxOn7mmr34Cfx8VAIz1+7l2blpfJScwRUDOtKuVQgju7UlIjSQr9bvZ8+RAhanZ/PToXH4N+IFVow5W9T6nIOI+AMvA2OADGCFiMxU1dTyPKr6gEf+XwHlK37sA85V1SIRCQfWO8fuBQZ6HLMS+MTjsh+o6n2nflumIblcyr8WbeWVhe4J5kIC/PjXt1s5PzEagN2H8kndd5RHL+/F9UPjWLzlAA/NSOHzSedVPKWsqsxcu5eR3aJ47Ire7oXnF7hrGLeP7AJAoL8fP+rTnq/W7adTRAtU3SOKjDGnz5eawzBgi6puU9ViYDpw9Qny3whMA1DVYlUtctKDq7ueiPQA2gGLT6bg5uxQVOo9e+ncjZn839fuOYHm/OZ8Jl3Sne+3HCQt8xhwvEnpx307EBEaxF+u6c/GfUd55ZvjzUtrM3LYdSifq5JiEBH+308HMCC2Ned2bcugzsdX+xrbvyPHikr596KtjOzWlrjI0Hq+Y2OaB1+CQydgt8d2hpPmRUTigQRggUdanIikOOf4m1Nr8DQBd03Bs2H6JyKSIiIzRKTa3kURuVtEkkUkOTs7u7ospp59sXYvg5+aS+bRwkrp/9uQ6V528tYhdG/XkgnndCYowI83f9hRsb9Xh5bEtw0DYEyf9lw9MIaXFmwhde/RinMH+fvxY2dhm9CgAD679zzeumNYpWud1y2KViEBlJQpN5xTvx3RxjQndd0hPQGYoaoVXydVdbeqDgC6A7eJSPtqjpnmsf0F0MU5Zi7wVnUXUtWpqjpUVYdGR0fX6U0Y33yyKoO84jK+WHs83pe5lIWbs7i4Z3TFqmORYUGMHxjDp6v2sC07lxU7D/Hjvh0qneuJK/sSERrIQzPWUlRaxqyUvVzYM7rS0pd+fuI122hQgB9XDOhIm9BAr3MaY06dL8FhD+D5lSzWSatO1Q/6Ck6NYT1wfnmaiCQBAaq60iPfQY+mqNeAIZgzbl1GDtOW76pxVbRjhSV8v+UgQKXgsHrXYQ7lFXNpn8rfAW4b2YWCkjImvb8aVbw+yNuEBfH0+P5s2HuUe95ZSebRIq5MivGprI+P68uc31xgaxcYU4d8CQ4rgEQRSRCRINwBYGbVTCLSC2gDLPFIixWRFs7rNsAoYLPHYRX9Ex7HeD69dBWw0bdbMXXp6S9TmfLJOn76ryXVPqi2cHM2xWUuxvRpz9qMHHYcyAPc/Q2B/sIFPSrX5vrGtGZYQiQb9x0lLrIFvTt6T053Wb8OjBvQkYWbs2kR6M+lvb3nTapOiyD/ahfBMcaculqDg6qWAvcBc3B/UH+oqhtE5CkRucoj6wRgepW+g97AMhFZC3wL/F1V13nsvx7vmsb9zrDXtcD9wO0ne1Pm9OQUlJC88zAju7Vl+4E8Ln9hsdcC9nM27CcqPJjHx/UBjtce5qVmMqJrW1qFBHqdd6IzyujHfTrUODPqk1f1JSo8mMv7d6x1eUtjTP3x6X+fqs4GZldJe7zK9hPVHDcXGHCC83pNaamqU4ApvpTL1I/v0g9Q5lJ+O6YHcZGhPPjRWh79dB29OrZkcOc2FJaU8c2mLK4a2Im4yFDO6dKGmWv3csWAjmzNzuPWEfHVnndMn/b8bkyPE05Y1zY8mPm/vZDgQHs+05iGZP8Dm7D1e3I4Wlhy0sct2JRF6xaBDIyLoH2rEF69ZQjtWwXz2KfrKS1z8cPWA+QVl/Hjvu5+hauSYkjPyq140nl076pjDtwC/P341ehEYiJanPD6rUMDrf/AmAZmwaGJyskv4ZpXvueVhVtP6jiXS/k2LYsLexwfbRQeHMDj4/qSuu8o7y7dyZz1mbQMDmBkN/c0FZf374i/n/DJqj306tDSnjUwpgmwRt0m6oetBygpU1btOnxSx6XsyeFAbjGXVFlE5/L+HTg/MYp//C8Nf3/h4l7tKoaVtg0P5rzuUSxKy2ZMn+prDcaYxsVqDk3U4i0HAHfTUtUpr09k4aYsRPAabSQiPHV1P4pKXRzJL/EaivqTwe7nIu1ZA2OaBgsOTdR36QcICvAjv7iMLVknXjPB08LNWQyKi6h2IZuEqDDuH92dNqGBXNSzcvC4KimGhQ9eRL9OrU+77MaYhmfBoQnaeTCPXYfymeBMJ7E244hPx2UdKyQlI8erScnTpIu7s+zRSwkLrtwiKSIkRIWdcpmNMWcXCw5N0OJ0d5PSrSPiaRkcwNrdR3w67tvN7jmqLupZc3AQ8Z7CwhjT9Nj/8ibou/QDxLQOoXu7cPrHtiYlw3uthOos2JRFu5bB9I1pVc8lNMac7Sw4NDFlLuWHrQcYlRiFiDAgNoJN+49WLKUJ8M+5aXyyKqPScYUlZXybls2lfdrX+PSyMab5sODQBLg8RiOlZBzhaGEpo5yFdQbGtaakTNm4zz0V9vYDebwwP53/N2dzpeMWpx8gv7jMRhsZYwALDo1e1tFCkp78Hw98sIacghK+c/obzuvWFoABsREAFU1LbzlrKuzLKWTptoMV55mzYT8tQwI4t2vbM1d4Y8xZyx6Ca+SW7zjEsaJSPl29h6XbDtIi0J9+nVrRNjwYgI6tQ4gKD2bt7iPkFpUyY2UGY/t14Lv0A3yyeg8ju0dRWuZi/sZMRns82GaMad7sk6CRS8nIIcjfj49/eS6hQf5sO5DHqO7Hn0EQEQbGtWZtxhE+XplBblEp91zYjbH9O/DVun0UFJexfMchDlfzYJsxpvmymkMjt3b3EfrEtGJIfCRf3n8+H6/KYGy/jpXyDIiNYP6mLP6zeBuDOkeQFBdBQUkZHyZn8L/U/azedYTgAD8u7Gkr6hlj3Kzm0IiVuZR1e3JIinU/lRwS6M/Nw+O9nm4eENsaVcg4XMDtzpoKw7pE0imiBR+v2sOcDfu5oEe0rZ9gjKlgwaER25qdS35xWUWnc02SnP3RLYMrahV+fsI1gzqxKC2bfTmF1qRkjKnEgkMjVv7kc1JcxAnztQkL4sqkGH47pkelDudrnMny/P3E5yU5jTHNg7UjNGJrM47QMjiArj7MafTijYO80rpFhzMsIZKWwQFEhHpPtGeMab4sODRiKRk59OvUGj+/U3+i+e07htVhiYwxTYVPzUoicpmIbBaRLSIyuZr9z4rIGucnTUSOOOnxIrLKSd8gIvd4HPONc87y49o56cEi8oFzrWUi0qVubrXh7T6Uz/o9vs1zVJui0jI27jtaa5NSbUIC/W1JTmOMl1prDiLiD7wMjAEygBUiMlNVU8vzqOoDHvl/BZS3YewDzlXVIhEJB9Y7x+519t+sqslVLvlz4LCqdheRCcDfgBtO8f7OKn+alco3adnMuOfcWjuRa7Nx3zFKyrRipJIxxtQlX2oOw4AtqrpNVYuB6cDVJ8h/IzANQFWLVbXISQ/28XpXA285r2cAo6WJzAS3OfMYxaUufvHOSrKOFZ7WuVKcNRoGnGbNwRhjquPLh3UnYLfHdoaT5kVE4oEEYIFHWpyIpDjn+JtHrQHgDadJ6Q8eAaDieqpaCuQAjX7Cn8KSMnYdyufHfdtzOL+Ye99dRXGp65TPt2b3EaLCg4lpHVKHpTTGGLe6Hso6AZihqhXzQ6vqblUdAHQHbhOR8hXob1bV/sD5zs+tJ3MhEblbRJJFJDk7O7uOil9/tmXnoQpXJsXw9+uSSN55mCe+2HDCY7KOFfKvb7dWmm67XEqG++G3JlKpMsacZXwJDnuAOI/tWCetOhNwmpSqcmoM63EHAlR1j/P7GPA+7uarStcTkQCgNXCwmvNNVdWhqjo0Ovrsn/YhPesYAN3bhTNuQAz3XNiN95ftYsGmzBqPeXrWRp75ahPPfLWpUvqxwhK2Zueedr+FMcbUxJfgsAJIFJEEEQnCHQBmVs0kIr2ANsASj7RYEWnhvG4DjAI2i0iAiEQ56YHAONyBA+fctzmvfwosUNXjCw80UluzcvETKtZZ/u2YHvTq0JIpn6wjp6DEK/+m/Uf5ImUvHVuH8OYPO5iX6g4ipWUu/jhzA6pwTkKbM3oPxpjmo9bg4LT73wfMATYCH6rqBhF5SkSu8sg6AZhe5YO8N7BMRNYC3wJ/V9V1uDun5zh9EWtw1xb+4xzzX6CtiGwBfgt4DZ1tjNKzcolvG0ZwgHvYaFCAH//vp0kcyC3m6VmpXvn/8b80woMC+Py+8+gb04qHZqxl96F8fj19DZ+s2sPvxvSwtReMMfXGp4fgVHU2MLtK2uNVtp+o5ri5wIBq0vOAITVcqxC4zpdyNSZbsnLp3i68Ulr/2Nbcc2FXXl64lcsHdOTinu4pLFbvOszc1Ex+N6YH7VqG8OKNgxj34nf86NlFFJSU8dgVvbnz/K4NcRvGmGbC5lY6A0rKXGw/kOcVHADuH51IYrtwfjN9Df/832b25RTwj/+lERkWxMRRCQB0jQ7n6fH9KHW5+NP4fhYYjDH1zqbPOAN2Hsyn1KUkVhMcggP8efWWIfz5y1ReXLiFlxZuwaXw2BW9CQ8+/vZcOziWy/t3tKeZjTFnhAWHM2CLx0il6nRvF84bE4ex+1A+7y/fxY4DedwyIt4rnwUGY8yZYsHhDNiSlQu4Z0E9kbjIUB65rNeZKJIxxpyQ9TmcAelZuXSKaEFYsMViY0zjYMHhDKhupJIxxpzNLDjUM5dL2ZptwcEY07hYcKhne44UUFjisuBgjGlULDjUs/I5laobxmqMMWcrCw515PXvtvP9lgNe6eUjlazmYIxpTCw41IG8olL+Mnsjr3+33WtfemYuUeHBRIQGNUDJjDHm1FhwqAMrdx6m1KWkO7UET2lZudakZIxpdCw41IGl29zLTew+nE9B8fGFeVwuJW3/MXp2aNlQRTPGmFNiwaEOLNl2ED8BVdiafbz2sOtQPgUlZfTuaMHBGNO4WHA4TXlFpaRk5DCmj3v10/LRSQCb9rtf9+zQqkHKZowxp8qCw2lK3nmYMpcy4ZzOBPoLaZnHaw6b9h9FBHq0tz4HY0zjYsHhNC3ZepBAf2F410gSosJI9wgOm/cfo0vbMEKDbE4lY0zjYsHhNC3ddpCk2AhCgwJIbNfSq1mpZ3vrbzDGND4WHE5DblEp6/bkcG4391rO3duFs+tQPoUlZRQUl7HjYB69rDPaGNMIWXvHaVix4xBlLmVEV3dw6NG+ZcWIpdIyRRV62TBWY0wj5FPNQUQuE5HNIrJFRCZXs/9ZEVnj/KSJyBEnPV5EVjnpG0TkHic9VES+FJFNTvozHue6XUSyPc53Zx3da51buu0gQf5+DO7cBoBEp+M5PTOXzc5IpV42UskY0wjVWnMQEX/gZWAMkAGsEJGZqppankdVH/DI/ytgkLO5DzhXVYtEJBxYLyIzgSPA31V1oYgEAfNFZKyqfuUc94Gq3lcH91fnPl+zhz1HCgCYs34/A+MiaBHkXr6zS9swAvyE9Kxj5BeX0SLQn86RoQ1ZXGOMOSW+NCsNA7ao6jYAEZkOXA2k1pD/RuCPAKpa7JEejFNTUdV8YGF5HhFZBcSeyg2cSRv25vDr6Wsqpf3s3C4Vr4MC/OgSFUZaZi55RaX06NASPz85s4U0xpg64Etw6ATs9tjOAIZXl1FE4oEEYIFHWhzwJdAdeEhV91Y5JgK4EnjeI/knInIBkAY8oKqe128w7y/bRXCAH4sfuZhWIYGIQHCAf6U8PdqHk7r3KEcLS/mR82CcMcY0NnU9WmkCMENVKyYYUtXdqjoAd3C4TUQqPjFFJACYBrxQXjMBvgC6OMfMBd6q7kIicreIJItIcnZ2dh3fhrfcolI+W72HcQNiaNcyhJBAf6/AANC9XUt2HMznUF6xzalkjGm0fAkOe4A4j+1YJ606E3B/2HtxagzrgfM9kqcC6ar6nEe+g6pa5Gy+Bgyp4XxTVXWoqg6Njo724TZOz+dr9pBXXMbNIzqfMJ/nDKzWGW2Maax8CQ4rgEQRSXA6jycAM6tmEpFeQBtgiUdarIi0cF63AUYBm53tp4HWwG+qnKejx+ZVwMaTuJ96oaq8v2wXvTq0ZFBcxAnz9vB46M2GsRpjGqtag4OqlgL3AXNwf1B/qKobROQpEbnKI+sEYLqqqkdab2CZiKwFvsU9QmmdiMQCvwf6AOVDXcuHrN7vDG9dC9wP3H6a93ja1mbksGHvUW4eEY/IiTuYu0SF4u8ntG8VTJswW+DHGNM4+fQQnKrOBmZXSXu8yvYT1Rw3FxhQTXoGUO2nrKpOAab4Uq4z5b2lOwkN8mf8wJha8wYH+JPYLpxOES3OQMmMMaZ+2BPStThWWMIXKXu5ZlAsLUMCfTrmX7cMISTQu7PaGGMaCwsOtfhmczaFJS6uHdzJ52O6RIXVY4mMMab+2cR7tZi/MZPIsKCKKTKMMaY5sOBwAiVlLhZsyuKSXu3wtyedjTHNiAWHE0jecZijhaVc2rtdQxfFGGPOKAsOJzBvYyZB/n6cn1j/D9kZY8zZxIJDDVSVeRszGdm9LWHB1m9vjGleLDjUYGt2LjsP5nNpb5s8zxjT/FhwqMHc1CwARlt/gzGmGbLgUIN5GzPp36k1HVvbk87GmObHgkM1DuYWsWrXYas1GGOaLQsO1UjZk4MqnNu1bUMXxRhjGoQFh2qkZx4DsMV6jDHNlgWHaqRl5tKuZTARoTbltjGmebLgUI20zGOVFu0xxpjmxoJDFS6Xkp6Za8HBGNOsWXCoIuNwAQUlZfRoH157ZmOMaaIsOFSR5nRG97DOaGNMM2bBoYrNTnBIbGc1B2NM82XBoYr0zGN0imjh85KgxhjTFPkUHETkMhHZLCJbRGRyNfufFZE1zk+aiBxx0uNFZJWTvkFE7vE4ZoiIrHPO+YKIiJMeKSJzRSTd+X1Gl2BLy8wl0fobjDHNXK3BQUT8gZeBsUAf4EYR6eOZR1UfUNWBqjoQeBH4xNm1DzjXSR8OTBaRGGffq8BdQKLzc5mTPhmYr6qJwHxn+4wocylbsm2kkjHG+FJzGAZsUdVtqloMTAeuPkH+G4FpAKparKpFTnpw+fVEpCPQSlWXqqoCbwPjnXxXA285r9/ySK93Ow/mUVzqsuBgjGn2fAkOnYDdHtsZTpoXEYkHEoAFHmlxIpLinONvqrrXOT6jhnO2V9V9zuv9QLULKojI3SKSLCLJ2dnZPtxG7SpGKlmzkjGmmavrDukJwAxVLStPUNXdqjoA6A7cJiI+r57j1Cq0hn1TVXWoqg6Njq6bZTzTMnMRge42UskY08z5Ehz2AHEe27FOWnUm4DQpVeXUGNYD5zvHx9Zwzkyn2am8+SnLhzLWic2Zx4hrE0pokC0Laoxp3nwJDiuARBFJEJEg3AFgZtVMItILaAMs8UiLFZEWzus2wChgs9NsdFRERjijlH4GfO4cNhO4zXl9m0d6vUu3OZWMMQbwITioailwHzAH2Ah8qKobROQpEbnKI+sEYLrTFFSuN7BMRNYC3wJ/V9V1zr57gdeALcBW4Csn/RlgjIikA5c62/WuuNTFtuw8628wxhjAp/YTVZ0NzK6S9niV7SeqOW4uMKCGcyYD/apJPwiM9qVcdWnHwTxKXWo1B2OMwZ6QrrD3SAEAcZG2ZrQxxlhwcBQUuwdYWWe0McZYcKiQXxEc/Bu4JMYY0/AsODjyS9zBoYUFB2OMseBQrqC4FLBmJWOMAQsOFcqblVoEWs3BGGMsODgKissIDvDD308auijGGNPgLDg48ovLrDPaGGMcFhwcecWl1t9gjDEOCw6OguIyG6lkjDEOCw6O/OIywiw4GGMMYMGhgtUcjDHmOAsOjvwS63MwxphyFhwc+VZzMMaYChYcHAXFZYTaA3DGGANYcKhgzzkYY8xxFhwc7g5p63Mwxhiw4ABASZmL4jKX1RyMMcZhwQFby8EYY6qy4MDxVeBstJIxxrj5FBxE5DIR2SwiW0RkcjX7nxWRNc5PmogccdIHisgSEdkgIikicoPHMYs9jtkrIp856ReJSI7Hvsfr5lZrlu+s5RBmfQ7GGANArZ+GIuIPvAyMATKAFSIyU1VTy/Oo6gMe+X8FDHI284GfqWq6iMQAK0VkjqoeUdXzPY75GPjc47KLVXXc6dzYyci3moMxxlTiS81hGLBFVbepajEwHbj6BPlvBKYBqGqaqqY7r/cCWUC0Z2YRaQVcAnx20qWvIwUl1udgjDGefAkOnYDdHtsZTpoXEYkHEoAF1ewbBgQBW6vsGg/MV9WjHmnnishaEflKRPrWcK27RSRZRJKzs7N9uI2aWYe0McZUVtcd0hOAGapa5pkoIh2Bd4CJquqqckxFTcOxCohX1STgRWqoUajqVFUdqqpDo6Ojq8vis/L1o1sEWp+DMcaAb8FhDxDnsR3rpFVnApU/6Mubjb4Efq+qS6vsi8LdbPVleZqqHlXVXOf1bCDQyVdvrOZgjDGV+RIcVgCJIpIgIkG4A8DMqplEpBfQBljikRYEfAq8raozqjn3T4FZqlrocUwHERHn9TCnjAd9v6WTl2fBwRhjKqm1HUVVS0XkPmAO4A+8rqobROQpIFlVywPFBGC6qqrH4dcDFwBtReR2J+12VV3jccwzVS75U+CXIlIKFAATqpyzzlU0K1lwMMYYwIfgABXNO7OrpD1eZfuJao57F3j3BOe9qJq0l4CXfClXXTnerGR9DsYYA/aENOB+Qjo4wA9/P2noohhjzFnBggM2XbcxxlRlwYHy4GBNSsYYU86CA1BQUmqd0cYY48GCA9asZIwxVVlwwB0cWtj60cYYU8GCA+4pu63mYIwxx1lwwDqkjTGmKgsOuJ9zsA5pY4w5zoID1iFtjDFVWXDAXXOwZiVjjDmu2QeH0jIXxWUuqzkYY4yHZh8c8m2JUGOM8dLsg0OBMyOrdUgbY8xxzT442CpwxhjjrdkHh7wiWz/aGGOqavbBocD6HIwxxkuzDw7WrGSMMd6afXCw9aONMcZbsw8Otn60McZ48yk4iMhlIrJZRLaIyORq9j8rImucnzQROeKkDxSRJSKyQURSROQGj2PeFJHtHscNdNJFRF5wrpUiIoPr5larVx4cwqzmYIwxFWr9uiwi/sDLwBggA1ghIjNVNbU8j6o+4JH/V8AgZzMf+JmqpotIDLBSROao6hFn/0OqOqPKJccCic7PcOBV53e9sOccjDHGmy81h2HAFlXdpqrFwHTg6hPkvxGYBqCqaaqa7rzeC2QB0bVc72rgbXVbCkSISEcfynlKrFnJGGO8+RIcOgG7PbYznDQvIhIPJAALqtk3DAgCtnok/9lpOnpWRIJP5noicreIJItIcnZ2tg+3Ub38klKCAvzw95NTPocxxjQ1dd0hPQGYoaplnonON/93gImq6nKSpwC9gHOASOCRk7mQqk5V1aGqOjQ6urbKSM0KbLpuY4zx4ktw2APEeWzHOmnVmYDTpFRORFoBXwK/d5qJAFDVfU7TURHwBu7mq5O93mnLKyoj1NaPNsaYSnwJDiuARBFJEJEg3AFgZtVMItILaAMs8UgLAj7F3Ycwo0r+js5vAcYD651dM4GfOaOWRgA5qrrvZG/MVwUlpdYZbYwxVdTaC6uqpSJyHzAH8AdeV9UNIvIUkKyq5YFiAjBdVdXj8OuBC4C2InK7k3a7qq4B3hORaECANcA9zv7ZwOXAFtyjnSae+u3VztaPNsYYbz59KqrqbNwf2p5pj1fZfqKa494F3q3hnJfUkK7AJF/KVRfybf1oY4zx0uyfkLYOaWOM8dbsg0N+cSlh1qxkjDGVNPvgUGDNSsYY46XZB4f8EmtWMsaYqiw4WM3BGGO8NOvgUFrmorjURagtEWqMMZU06+CQb0uEGmNMtZp1cLDpuo0xpnrNOjjY+tHGGFO9Zh4c3OtHW3AwxpjKmnVwKLCFfowxplrNOjhYs5IxxlTPggPWIW2MMVU16+AQ3TKIsf060DYsuPbMxhjTjDTrxvYh8ZEMiY9s6GIYY8xZp1nXHIwxxlTPgoMxxhgvFhyMMcZ4seBgjDHGiwUHY4wxXiw4GGOM8WLBwRhjjBcLDsYYY7yIqjZ0GU6biGQDO0/ikCjgQD0V52zWHO+7Od4zNM/7bo73DKd33/GqGl3djiYRHE6WiCSr6tCGLseZ1hzvuzneMzTP+26O9wz1d9/WrGSMMcaLBQdjjDFemmtwmNrQBWggzfG+m+M9Q/O87+Z4z1BP990s+xyMMcacWHOtORhjjDkBCw7GGGO8NLvgICKXichmEdkiIpMbujz1QUTiRGShiKSKyAYR+bWTHikic0Uk3fndpqHLWh9ExF9EVovILGc7QUSWOe/5ByIS1NBlrEsiEiEiM0Rkk4hsFJFzm8N7LSIPOP++14vINBEJaWrvtYi8LiJZIrLeI63a91bcXnDuPUVEBp/OtZtVcBARf+BlYCzQB7hRRPo0bKnqRSnwO1XtA4wAJjn3ORmYr6qJwHxnuyn6NbDRY/tvwLOq2h04DPy8QUpVf54HvlbVXkAS7ntv0u+1iHQC7geGqmo/wB+YQNN7r98ELquSVtN7OxZIdH7uBl49nQs3q+AADAO2qOo2VS0GpgNXN3CZ6pyq7lPVVc7rY7g/LDrhvte3nGxvAeMbpID1SERigSuA15xtAS4BZjhZmtR9i0hr4ALgvwCqWqyqR2gG7zXuZY5biEgAEArso4m916q6CDhUJbmm9/Zq4G11WwpEiEjHU712cwsOnYDdHtsZTlqTJSJdgEHAMqC9qu5zdu0H2jdUuerRc8DDgMvZbgscUdVSZ7upvecJQDbwhtOU9pqIhNHE32tV3QP8HdiFOyjkACtp2u91uZre2zr9fGtuwaFZEZFw4GPgN6p61HOfuscwN6lxzCIyDshS1ZUNXZYzKAAYDLyqqoOAPKo0ITXR97oN7m/KCUAMEIZ380uTV5/vbXMLDnuAOI/tWCetyRGRQNyB4T1V/cRJziyvZjq/sxqqfPXkPOAqEdmBu8nwEtzt8RFO0wM0vfc8A8hQ1WXO9gzcwaKpv9eXAttVNVtVS4BPcL//Tfm9LlfTe1unn2/NLTisABKdEQ1BuDuwZjZwmeqc087+X2Cjqv7TY9dM4Dbn9W3A52e6bPVJVaeoaqyqdsH93i5Q1ZuBhcBPnWxN6r5VdT+wW0R6OkmjgVSa+HuNuzlphIiEOv/ey++7yb7XHmp6b2cCP3NGLY0Acjyan05as3tCWkQux90u7Q+8rqp/btgS1T0RGQUsBtZxvO39Udz9Dh8CnXFPcX69qlbt7GoSROQi4EFVHSciXXHXJCKB1cAtqlrUgMWrUyIyEHcHfBCwDZiI+4tfk36vReRJ4Abco/NWA3fibmNvMu+1iEwDLsI9LXcm8EfgM6p5b50g+RLu5rV8YKKqJp/ytZtbcDDGGFO75tasZIwxxgcWHIwxxnix4GCMMcaLBQdjjDFeLDgYY4zxYsHBGGOMFwsOxhhjvPx/LM1+bUW5qW0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(model_fit.history)\n",
    "history_df.index += 1\n",
    "\n",
    "history_df.plot(y='accuracy')\n",
    "history_df.plot(y='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 0s - loss: 0.5808 - accuracy: 0.7277 - 265ms/epoch - 1ms/step\n",
      "Model loss: 0.5808, accuracy: 0.7277\n"
     ]
    }
   ],
   "source": [
    "#  evaluate the model\n",
    "model_loss, model_acc = nn.evaluate(X_test_scaled, y_test,verbose=2)\n",
    "print(f'Model loss: {model_loss:.4f}, accuracy: {model_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More layers brought the performance up by a little bit. Next I will try a different activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 90)                3690      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                4550      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,291\n",
      "Trainable params: 8,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_count = len(X_train_scaled[0])\n",
    "node_count = 90\n",
    "node_count_2 = 50\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count, activation='sigmoid', input_shape=(feature_count,)))\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count_2, activation='sigmoid'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# check structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  compile the model\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "858/858 [==============================] - 1s 933us/step - loss: 0.5943 - accuracy: 0.7073\n",
      "Epoch 2/100\n",
      "858/858 [==============================] - 1s 971us/step - loss: 0.5765 - accuracy: 0.7209\n",
      "Epoch 3/100\n",
      "858/858 [==============================] - 1s 964us/step - loss: 0.5699 - accuracy: 0.7229\n",
      "Epoch 4/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5648 - accuracy: 0.7251\n",
      "Epoch 5/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5608 - accuracy: 0.7258\n",
      "Epoch 6/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5589 - accuracy: 0.7285\n",
      "Epoch 7/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5574 - accuracy: 0.7294\n",
      "Epoch 8/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5559 - accuracy: 0.7295\n",
      "Epoch 9/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5552 - accuracy: 0.7307\n",
      "Epoch 10/100\n",
      "858/858 [==============================] - 1s 985us/step - loss: 0.5544 - accuracy: 0.7300\n",
      "Epoch 11/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5529 - accuracy: 0.7317\n",
      "Epoch 12/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5524 - accuracy: 0.7311\n",
      "Epoch 13/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7303\n",
      "Epoch 14/100\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5516 - accuracy: 0.7306: 0s - loss: 0.5517 - accuracy: 0.\n",
      "Epoch 15/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5508 - accuracy: 0.7313: \n",
      "Epoch 16/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5501 - accuracy: 0.7308\n",
      "Epoch 17/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5498 - accuracy: 0.7312\n",
      "Epoch 18/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5496 - accuracy: 0.7315\n",
      "Epoch 19/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5491 - accuracy: 0.7314: 0s - loss: 0.5506 - accu\n",
      "Epoch 20/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5491 - accuracy: 0.7326\n",
      "Epoch 21/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5488 - accuracy: 0.7314\n",
      "Epoch 22/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.7327\n",
      "Epoch 23/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7324\n",
      "Epoch 24/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5478 - accuracy: 0.7328\n",
      "Epoch 25/100\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5476 - accuracy: 0.7336\n",
      "Epoch 26/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7332: 0s - loss: 0.5446 - ac\n",
      "Epoch 27/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5469 - accuracy: 0.7337\n",
      "Epoch 28/100\n",
      "858/858 [==============================] - 1s 998us/step - loss: 0.5466 - accuracy: 0.7333\n",
      "Epoch 29/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.7337\n",
      "Epoch 30/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5461 - accuracy: 0.7337\n",
      "Epoch 31/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5460 - accuracy: 0.7340\n",
      "Epoch 32/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7341\n",
      "Epoch 33/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7352\n",
      "Epoch 34/100\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7342: 0s -\n",
      "Epoch 35/100\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7346: 0s - loss: 0.5441 - ac\n",
      "Epoch 36/100\n",
      "858/858 [==============================] - 1s 832us/step - loss: 0.5453 - accuracy: 0.7350\n",
      "Epoch 37/100\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5452 - accuracy: 0.7356\n",
      "Epoch 38/100\n",
      "858/858 [==============================] - 1s 858us/step - loss: 0.5447 - accuracy: 0.7352\n",
      "Epoch 39/100\n",
      "858/858 [==============================] - 1s 951us/step - loss: 0.5445 - accuracy: 0.7353\n",
      "Epoch 40/100\n",
      "858/858 [==============================] - 1s 839us/step - loss: 0.5448 - accuracy: 0.7353\n",
      "Epoch 41/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7346\n",
      "Epoch 42/100\n",
      "858/858 [==============================] - 1s 764us/step - loss: 0.5441 - accuracy: 0.7357\n",
      "Epoch 43/100\n",
      "858/858 [==============================] - 1s 676us/step - loss: 0.5437 - accuracy: 0.7365\n",
      "Epoch 44/100\n",
      "858/858 [==============================] - 1s 682us/step - loss: 0.5437 - accuracy: 0.7364\n",
      "Epoch 45/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7347\n",
      "Epoch 46/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7361\n",
      "Epoch 47/100\n",
      "858/858 [==============================] - 1s 866us/step - loss: 0.5432 - accuracy: 0.7364\n",
      "Epoch 48/100\n",
      "858/858 [==============================] - 1s 890us/step - loss: 0.5429 - accuracy: 0.7356\n",
      "Epoch 49/100\n",
      "858/858 [==============================] - 1s 915us/step - loss: 0.5430 - accuracy: 0.7367\n",
      "Epoch 50/100\n",
      "858/858 [==============================] - 1s 764us/step - loss: 0.5423 - accuracy: 0.7357\n",
      "Epoch 51/100\n",
      "858/858 [==============================] - 1s 769us/step - loss: 0.5430 - accuracy: 0.7365\n",
      "Epoch 52/100\n",
      "858/858 [==============================] - 1s 855us/step - loss: 0.5426 - accuracy: 0.7374\n",
      "Epoch 53/100\n",
      "858/858 [==============================] - 1s 827us/step - loss: 0.5424 - accuracy: 0.7355\n",
      "Epoch 54/100\n",
      "858/858 [==============================] - 1s 691us/step - loss: 0.5419 - accuracy: 0.7369\n",
      "Epoch 55/100\n",
      "858/858 [==============================] - 1s 671us/step - loss: 0.5421 - accuracy: 0.7372\n",
      "Epoch 56/100\n",
      "858/858 [==============================] - 1s 694us/step - loss: 0.5417 - accuracy: 0.7369\n",
      "Epoch 57/100\n",
      "858/858 [==============================] - 1s 672us/step - loss: 0.5418 - accuracy: 0.7370\n",
      "Epoch 58/100\n",
      "858/858 [==============================] - 1s 683us/step - loss: 0.5416 - accuracy: 0.7363\n",
      "Epoch 59/100\n",
      "858/858 [==============================] - 1s 777us/step - loss: 0.5417 - accuracy: 0.7377\n",
      "Epoch 60/100\n",
      "858/858 [==============================] - 1s 752us/step - loss: 0.5412 - accuracy: 0.7376\n",
      "Epoch 61/100\n",
      "858/858 [==============================] - 1s 724us/step - loss: 0.5411 - accuracy: 0.7378\n",
      "Epoch 62/100\n",
      "858/858 [==============================] - 1s 732us/step - loss: 0.5411 - accuracy: 0.7369\n",
      "Epoch 63/100\n",
      "858/858 [==============================] - 1s 717us/step - loss: 0.5411 - accuracy: 0.7377\n",
      "Epoch 64/100\n",
      "858/858 [==============================] - 1s 749us/step - loss: 0.5410 - accuracy: 0.7375\n",
      "Epoch 65/100\n",
      "858/858 [==============================] - 1s 718us/step - loss: 0.5408 - accuracy: 0.7377\n",
      "Epoch 66/100\n",
      "858/858 [==============================] - 1s 737us/step - loss: 0.5409 - accuracy: 0.7377\n",
      "Epoch 67/100\n",
      "858/858 [==============================] - 1s 739us/step - loss: 0.5406 - accuracy: 0.7380\n",
      "Epoch 68/100\n",
      "858/858 [==============================] - 1s 743us/step - loss: 0.5406 - accuracy: 0.7379\n",
      "Epoch 69/100\n",
      "858/858 [==============================] - 1s 690us/step - loss: 0.5404 - accuracy: 0.7380\n",
      "Epoch 70/100\n",
      "858/858 [==============================] - 1s 724us/step - loss: 0.5403 - accuracy: 0.7381\n",
      "Epoch 71/100\n",
      "858/858 [==============================] - 1s 799us/step - loss: 0.5399 - accuracy: 0.7379\n",
      "Epoch 72/100\n",
      "858/858 [==============================] - 1s 783us/step - loss: 0.5400 - accuracy: 0.7377\n",
      "Epoch 73/100\n",
      "858/858 [==============================] - 1s 816us/step - loss: 0.5401 - accuracy: 0.7379\n",
      "Epoch 74/100\n",
      "858/858 [==============================] - 1s 808us/step - loss: 0.5398 - accuracy: 0.7385\n",
      "Epoch 75/100\n",
      "858/858 [==============================] - 1s 736us/step - loss: 0.5398 - accuracy: 0.7381\n",
      "Epoch 76/100\n",
      "858/858 [==============================] - 1s 703us/step - loss: 0.5396 - accuracy: 0.7382\n",
      "Epoch 77/100\n",
      "858/858 [==============================] - 1s 731us/step - loss: 0.5394 - accuracy: 0.7389\n",
      "Epoch 78/100\n",
      "858/858 [==============================] - 1s 766us/step - loss: 0.5395 - accuracy: 0.7384\n",
      "Epoch 79/100\n",
      "858/858 [==============================] - 1s 767us/step - loss: 0.5394 - accuracy: 0.7381\n",
      "Epoch 80/100\n",
      "858/858 [==============================] - 1s 841us/step - loss: 0.5395 - accuracy: 0.7389\n",
      "Epoch 81/100\n",
      "858/858 [==============================] - 1s 749us/step - loss: 0.5392 - accuracy: 0.7391\n",
      "Epoch 82/100\n",
      "858/858 [==============================] - 1s 733us/step - loss: 0.5392 - accuracy: 0.7389\n",
      "Epoch 83/100\n",
      "858/858 [==============================] - 1s 716us/step - loss: 0.5391 - accuracy: 0.7392\n",
      "Epoch 84/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7392\n",
      "Epoch 85/100\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7385\n",
      "Epoch 86/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7392\n",
      "Epoch 87/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7391\n",
      "Epoch 88/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5386 - accuracy: 0.7385: 0s - l\n",
      "Epoch 89/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5385 - accuracy: 0.7399\n",
      "Epoch 90/100\n",
      "858/858 [==============================] - 1s 925us/step - loss: 0.5384 - accuracy: 0.7387\n",
      "Epoch 91/100\n",
      "858/858 [==============================] - 1s 999us/step - loss: 0.5384 - accuracy: 0.7393\n",
      "Epoch 92/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7390\n",
      "Epoch 93/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7393\n",
      "Epoch 94/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7393\n",
      "Epoch 95/100\n",
      "858/858 [==============================] - 1s 913us/step - loss: 0.5382 - accuracy: 0.7391\n",
      "Epoch 96/100\n",
      "858/858 [==============================] - 1s 930us/step - loss: 0.5380 - accuracy: 0.7396\n",
      "Epoch 97/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7396\n",
      "Epoch 98/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7394\n",
      "Epoch 99/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.7389\n",
      "Epoch 100/100\n",
      "858/858 [==============================] - 1s 942us/step - loss: 0.5376 - accuracy: 0.7397\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model_fit = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 0s - loss: 0.5675 - accuracy: 0.7265 - 202ms/epoch - 941us/step\n",
      "Model loss: 0.5675, accuracy: 0.7265\n"
     ]
    }
   ],
   "source": [
    "#  evaluate the model\n",
    "model_loss, model_acc = nn.evaluate(X_test_scaled, y_test,verbose=2)\n",
    "print(f'Model loss: {model_loss:.4f}, accuracy: {model_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will add more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 90)                3690      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 50)                4550      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,291\n",
      "Trainable params: 8,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the new neural network model\n",
    "feature_count = len(X_train_scaled[0])\n",
    "node_count = 90\n",
    "node_count_2 = 50\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count, activation='relu', input_shape=(feature_count,)))\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count_2, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# check structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  compile the model\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7219\n",
      "Epoch 2/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5565 - accuracy: 0.7298\n",
      "Epoch 3/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5537 - accuracy: 0.7302\n",
      "Epoch 4/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5525 - accuracy: 0.7310\n",
      "Epoch 5/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5512 - accuracy: 0.7322\n",
      "Epoch 6/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5498 - accuracy: 0.7331: 0s - loss: 0.5515 - accuracy: 0. - ETA: 0s - loss: 0.5512 - accuracy\n",
      "Epoch 7/250\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5496 - accuracy: 0.7330\n",
      "Epoch 8/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5491 - accuracy: 0.7330: 0s\n",
      "Epoch 9/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5484 - accuracy: 0.7341\n",
      "Epoch 10/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7337\n",
      "Epoch 11/250\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5475 - accuracy: 0.7348: 0s - loss: 0.5478 - accura - ETA: 0s - loss: 0.5\n",
      "Epoch 12/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7353\n",
      "Epoch 13/250\n",
      "858/858 [==============================] - 1s 1000us/step - loss: 0.5467 - accuracy: 0.7354\n",
      "Epoch 14/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7357\n",
      "Epoch 15/250\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5462 - accuracy: 0.7349\n",
      "Epoch 16/250\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5459 - accuracy: 0.7354: 0s - loss: 0.5438 - accuracy - ETA: 0s - loss: 0.5441 - accura - ETA: 0s - loss: 0.5\n",
      "Epoch 17/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7354\n",
      "Epoch 18/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7359\n",
      "Epoch 19/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7356\n",
      "Epoch 20/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7362\n",
      "Epoch 21/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7360\n",
      "Epoch 22/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7367\n",
      "Epoch 23/250\n",
      "858/858 [==============================] - 1s 980us/step - loss: 0.5442 - accuracy: 0.7368\n",
      "Epoch 24/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7360\n",
      "Epoch 25/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5439 - accuracy: 0.7374\n",
      "Epoch 26/250\n",
      "858/858 [==============================] - 1s 993us/step - loss: 0.5436 - accuracy: 0.7361\n",
      "Epoch 27/250\n",
      "858/858 [==============================] - 1s 991us/step - loss: 0.5436 - accuracy: 0.7371\n",
      "Epoch 28/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7368\n",
      "Epoch 29/250\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5433 - accuracy: 0.7371\n",
      "Epoch 30/250\n",
      "858/858 [==============================] - 1s 933us/step - loss: 0.5427 - accuracy: 0.7378\n",
      "Epoch 31/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7375\n",
      "Epoch 32/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7377\n",
      "Epoch 33/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7375\n",
      "Epoch 34/250\n",
      "858/858 [==============================] - 1s 980us/step - loss: 0.5425 - accuracy: 0.7375\n",
      "Epoch 35/250\n",
      "858/858 [==============================] - 1s 985us/step - loss: 0.5422 - accuracy: 0.7383\n",
      "Epoch 36/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7379\n",
      "Epoch 37/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7374\n",
      "Epoch 38/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7377\n",
      "Epoch 39/250\n",
      "858/858 [==============================] - 1s 983us/step - loss: 0.5416 - accuracy: 0.7381\n",
      "Epoch 40/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7386\n",
      "Epoch 41/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7380\n",
      "Epoch 42/250\n",
      "858/858 [==============================] - 1s 937us/step - loss: 0.5413 - accuracy: 0.7388\n",
      "Epoch 43/250\n",
      "858/858 [==============================] - 1s 976us/step - loss: 0.5411 - accuracy: 0.7387\n",
      "Epoch 44/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5411 - accuracy: 0.7382\n",
      "Epoch 45/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5408 - accuracy: 0.7383\n",
      "Epoch 46/250\n",
      "858/858 [==============================] - 1s 988us/step - loss: 0.5410 - accuracy: 0.7385\n",
      "Epoch 47/250\n",
      "858/858 [==============================] - 1s 982us/step - loss: 0.5408 - accuracy: 0.7386\n",
      "Epoch 48/250\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5408 - accuracy: 0.7387\n",
      "Epoch 49/250\n",
      "858/858 [==============================] - 1s 857us/step - loss: 0.5404 - accuracy: 0.7385\n",
      "Epoch 50/250\n",
      "858/858 [==============================] - 1s 951us/step - loss: 0.5404 - accuracy: 0.7391\n",
      "Epoch 51/250\n",
      "858/858 [==============================] - 1s 939us/step - loss: 0.5400 - accuracy: 0.7380\n",
      "Epoch 52/250\n",
      "858/858 [==============================] - 1s 989us/step - loss: 0.5398 - accuracy: 0.7385\n",
      "Epoch 53/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5399 - accuracy: 0.7388\n",
      "Epoch 54/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.7390\n",
      "Epoch 55/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5400 - accuracy: 0.7391\n",
      "Epoch 56/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5395 - accuracy: 0.7395\n",
      "Epoch 57/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5399 - accuracy: 0.7391\n",
      "Epoch 58/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7383: 0s - loss: 0.5396 - accuracy:  - ETA: 0s - loss: 0.5407 - accura\n",
      "Epoch 59/250\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5396 - accuracy: 0.7387: 1s\n",
      "Epoch 60/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7389\n",
      "Epoch 61/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5394 - accuracy: 0.7388\n",
      "Epoch 62/250\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5396 - accuracy: 0.7388\n",
      "Epoch 63/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5392 - accuracy: 0.7385\n",
      "Epoch 64/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.7392\n",
      "Epoch 65/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5390 - accuracy: 0.7394\n",
      "Epoch 66/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7391\n",
      "Epoch 67/250\n",
      "858/858 [==============================] - 1s 955us/step - loss: 0.5391 - accuracy: 0.7393\n",
      "Epoch 68/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.7402\n",
      "Epoch 69/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7389\n",
      "Epoch 70/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7392: 0s - loss: 0.5353 - \n",
      "Epoch 71/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7392\n",
      "Epoch 72/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7387\n",
      "Epoch 73/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7400: 0s - loss: 0.540\n",
      "Epoch 74/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7390: 0s - loss: 0.537\n",
      "Epoch 75/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.7396\n",
      "Epoch 76/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7396\n",
      "Epoch 77/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7397\n",
      "Epoch 78/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7396\n",
      "Epoch 79/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5385 - accuracy: 0.7399\n",
      "Epoch 80/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7397\n",
      "Epoch 81/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7394\n",
      "Epoch 82/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5385 - accuracy: 0.7397\n",
      "Epoch 83/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7401\n",
      "Epoch 84/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7397\n",
      "Epoch 85/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.7400\n",
      "Epoch 86/250\n",
      "858/858 [==============================] - 1s 993us/step - loss: 0.5379 - accuracy: 0.7394\n",
      "Epoch 87/250\n",
      "858/858 [==============================] - 1s 989us/step - loss: 0.5377 - accuracy: 0.7399\n",
      "Epoch 88/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.7397\n",
      "Epoch 89/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.7394\n",
      "Epoch 90/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5379 - accuracy: 0.7399\n",
      "Epoch 91/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7399\n",
      "Epoch 92/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.7402\n",
      "Epoch 93/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7398\n",
      "Epoch 94/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7400\n",
      "Epoch 95/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7396\n",
      "Epoch 96/250\n",
      "858/858 [==============================] - 1s 951us/step - loss: 0.5375 - accuracy: 0.7395\n",
      "Epoch 97/250\n",
      "858/858 [==============================] - 1s 978us/step - loss: 0.5374 - accuracy: 0.7402\n",
      "Epoch 98/250\n",
      "858/858 [==============================] - 1s 948us/step - loss: 0.5376 - accuracy: 0.7396\n",
      "Epoch 99/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.7398\n",
      "Epoch 100/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7396\n",
      "Epoch 101/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5378 - accuracy: 0.7396\n",
      "Epoch 102/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7400\n",
      "Epoch 103/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7401\n",
      "Epoch 104/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7403: 0s - los\n",
      "Epoch 105/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7398\n",
      "Epoch 106/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7397\n",
      "Epoch 107/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7401\n",
      "Epoch 108/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7404\n",
      "Epoch 109/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7400: 0s\n",
      "Epoch 110/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7397: 0s - loss: 0.5374 - accuracy: 0.\n",
      "Epoch 111/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7399\n",
      "Epoch 112/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7400\n",
      "Epoch 113/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7400\n",
      "Epoch 114/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7398\n",
      "Epoch 115/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7400\n",
      "Epoch 116/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7400\n",
      "Epoch 117/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7399\n",
      "Epoch 118/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7402\n",
      "Epoch 119/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7404: 0s - loss: 0.5371 - accuracy: \n",
      "Epoch 120/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7403\n",
      "Epoch 121/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7402\n",
      "Epoch 122/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7406\n",
      "Epoch 123/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7397\n",
      "Epoch 124/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7404\n",
      "Epoch 125/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7404\n",
      "Epoch 126/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7399\n",
      "Epoch 127/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7404\n",
      "Epoch 128/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7407\n",
      "Epoch 129/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7403\n",
      "Epoch 130/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7402\n",
      "Epoch 131/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7402\n",
      "Epoch 132/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7399: 0s - loss: 0.5367 - accuracy: 0.74 - ETA: 0s - loss: 0.5367 - ac\n",
      "Epoch 133/250\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5361 - accuracy: 0.7406: 0s - loss: 0.5355 - accu\n",
      "Epoch 134/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5364 - accuracy: 0.7404\n",
      "Epoch 135/250\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5387 - accuracy: 0.7400: 0s - loss: 0.5369 - accu\n",
      "Epoch 136/250\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5361 - accuracy: 0.7404\n",
      "Epoch 137/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7403\n",
      "Epoch 138/250\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5361 - accuracy: 0.7403\n",
      "Epoch 139/250\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5360 - accuracy: 0.7404: 1s - loss: 0.5260 - accuracy:  - ETA: 1s -\n",
      "Epoch 140/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7410\n",
      "Epoch 141/250\n",
      "858/858 [==============================] - 4s 4ms/step - loss: 0.5372 - accuracy: 0.7401\n",
      "Epoch 142/250\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5363 - accuracy: 0.7406: 0s - loss: 0.5368 - \n",
      "Epoch 143/250\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5361 - accuracy: 0.7401\n",
      "Epoch 144/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7404\n",
      "Epoch 145/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7402\n",
      "Epoch 146/250\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5359 - accuracy: 0.7407\n",
      "Epoch 147/250\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5362 - accuracy: 0.7409\n",
      "Epoch 148/250\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5358 - accuracy: 0.7407: 1s - loss: 0.5359 - accu - ETA: 0s - loss: 0.5336 - accura - ETA: 0s - ETA: 0s - loss: 0.5338 - accuracy - ETA: 0s - loss: 0.5347 - accura\n",
      "Epoch 149/250\n",
      "858/858 [==============================] - 5s 5ms/step - loss: 0.5363 - accuracy: 0.7402: 0s - loss: 0.5353 \n",
      "Epoch 150/250\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5363 - accuracy: 0.7406\n",
      "Epoch 151/250\n",
      "858/858 [==============================] - 4s 5ms/step - loss: 0.5360 - accuracy: 0.7404\n",
      "Epoch 152/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5364 - accuracy: 0.7402: 1s - los\n",
      "Epoch 153/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7404\n",
      "Epoch 154/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7404\n",
      "Epoch 155/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7404\n",
      "Epoch 156/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7405\n",
      "Epoch 157/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7397\n",
      "Epoch 158/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7399\n",
      "Epoch 159/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7403: 0s - loss: 0.5391 - ac - ETA: 0s - loss: 0.5363 - accuracy: 0.\n",
      "Epoch 160/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7404\n",
      "Epoch 161/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7401: \n",
      "Epoch 162/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5364 - accuracy: 0.7405: 1s - loss: 0.5350 - accuracy: 0. - ETA: 1s - loss: 0.5343 -  - ETA: 0s - loss: 0.5366 - ac - ETA: 0s - loss: 0.5349 - accura\n",
      "Epoch 163/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7401\n",
      "Epoch 164/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7411: 0s - loss: 0.5366 - accuracy\n",
      "Epoch 165/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7406\n",
      "Epoch 166/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7402\n",
      "Epoch 167/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5359 - accuracy: 0.7406: \n",
      "Epoch 168/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7401\n",
      "Epoch 169/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7397\n",
      "Epoch 170/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7403\n",
      "Epoch 171/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7407\n",
      "Epoch 172/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7397\n",
      "Epoch 173/250\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5366 - accuracy: 0.7397\n",
      "Epoch 174/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5360 - accuracy: 0.7407\n",
      "Epoch 175/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7407\n",
      "Epoch 176/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7403\n",
      "Epoch 177/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5355 - accuracy: 0.7403\n",
      "Epoch 178/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7407\n",
      "Epoch 179/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7409\n",
      "Epoch 180/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7406\n",
      "Epoch 181/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7411\n",
      "Epoch 182/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7408\n",
      "Epoch 183/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7406\n",
      "Epoch 184/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7408\n",
      "Epoch 185/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7406\n",
      "Epoch 186/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7407\n",
      "Epoch 187/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7406\n",
      "Epoch 188/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7407\n",
      "Epoch 189/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7404\n",
      "Epoch 190/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7407\n",
      "Epoch 191/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7406\n",
      "Epoch 192/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5350 - accuracy: 0.7401: 0s - los - ETA: 0s - loss: 0.5355 - accura\n",
      "Epoch 193/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7404\n",
      "Epoch 194/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7408\n",
      "Epoch 195/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7409\n",
      "Epoch 196/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7407\n",
      "Epoch 197/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7405\n",
      "Epoch 198/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7406: 0s - loss: 0.5345 - accuracy: \n",
      "Epoch 199/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7406: 0s - loss: 0.5351 - accuracy: 0. - ETA: 0s - loss: 0.5348 - accu\n",
      "Epoch 200/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5354 - accuracy: 0.7409\n",
      "Epoch 201/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7409\n",
      "Epoch 202/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7403:  - ETA: 0s - loss: - ETA: 0s - loss: 0.5364 - accura\n",
      "Epoch 203/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7405\n",
      "Epoch 204/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7409\n",
      "Epoch 205/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7409\n",
      "Epoch 206/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7407\n",
      "Epoch 207/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7409\n",
      "Epoch 208/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7406\n",
      "Epoch 209/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7406: 0s - loss: 0.531\n",
      "Epoch 210/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7407\n",
      "Epoch 211/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7405\n",
      "Epoch 212/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7408\n",
      "Epoch 213/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7407\n",
      "Epoch 214/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7407: 0s - loss: 0.5343  - ETA: 0s - loss: 0.5353 - accuracy\n",
      "Epoch 215/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7401: 0s - loss: 0.5346  - ETA: 0s - loss: 0.5358 - ac\n",
      "Epoch 216/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7409\n",
      "Epoch 217/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7405\n",
      "Epoch 218/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7403\n",
      "Epoch 219/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7407\n",
      "Epoch 220/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7407\n",
      "Epoch 221/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7407\n",
      "Epoch 222/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5351 - accuracy: 0.7406\n",
      "Epoch 223/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7407\n",
      "Epoch 224/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5345 - accuracy: 0.7413: 0s - loss:\n",
      "Epoch 225/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7412\n",
      "Epoch 226/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7406\n",
      "Epoch 227/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7407\n",
      "Epoch 228/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7409\n",
      "Epoch 229/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5345 - accuracy: 0.7408\n",
      "Epoch 230/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5359 - accuracy: 0.7411: 0s - loss: 0.533\n",
      "Epoch 231/250\n",
      "858/858 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.7414 ETA: 0s - loss: 0.5339  - 2s 3ms/step - loss: 0.5352 - accuracy: 0.7409\n",
      "Epoch 232/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5348 - accuracy: 0.7411\n",
      "Epoch 233/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7408\n",
      "Epoch 234/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5347 - accuracy: 0.7411\n",
      "Epoch 235/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7401\n",
      "Epoch 236/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7403\n",
      "Epoch 237/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7409\n",
      "Epoch 238/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7404\n",
      "Epoch 239/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7410\n",
      "Epoch 240/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7405\n",
      "Epoch 241/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5346 - accuracy: 0.7408\n",
      "Epoch 242/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7406\n",
      "Epoch 243/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7414\n",
      "Epoch 244/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7412: 0s - loss: 0.5348 - accuracy: 0.\n",
      "Epoch 245/250\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5345 - accuracy: 0.7410\n",
      "Epoch 246/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7404\n",
      "Epoch 247/250\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5383 - accuracy: 0.7407\n",
      "Epoch 248/250\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7410\n",
      "Epoch 249/250\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7404\n",
      "Epoch 250/250\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7407\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model_fit = nn.fit(X_train_scaled, y_train, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 0s - loss: 0.5974 - accuracy: 0.7290 - 210ms/epoch - 978us/step\n",
      "Model loss: 0.5974, accuracy: 0.7290\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_acc = nn.evaluate(X_test_scaled, y_test,verbose=2)\n",
    "print(f'Model loss: {model_loss:.4f}, accuracy: {model_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I will try more epochs, additional layers, and varying activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 100)               4100      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the new neural network model\n",
    "feature_count = len(X_train_scaled[0])\n",
    "node_count = 100\n",
    "node_count_2 = 50\n",
    "node_count_3 = 25\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count, activation='relu', input_shape=(feature_count,)))\n",
    "# second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count_2, activation='relu'))\n",
    "# third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(node_count_3, activation='sigmoid'))\n",
    "\n",
    "# output layer\n",
    "nn.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# check structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  compile the model\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5689 - accuracy: 0.7213\n",
      "Epoch 2/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5564 - accuracy: 0.7288\n",
      "Epoch 3/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5546 - accuracy: 0.7298\n",
      "Epoch 4/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5523 - accuracy: 0.7319\n",
      "Epoch 5/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5514 - accuracy: 0.7320: 0s - loss: 0.5509 \n",
      "Epoch 6/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5507 - accuracy: 0.7330\n",
      "Epoch 7/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5493 - accuracy: 0.7328\n",
      "Epoch 8/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5493 - accuracy: 0.7333\n",
      "Epoch 9/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5486 - accuracy: 0.7343\n",
      "Epoch 10/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.7344\n",
      "Epoch 11/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5479 - accuracy: 0.7347\n",
      "Epoch 12/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5472 - accuracy: 0.7351\n",
      "Epoch 13/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.7349\n",
      "Epoch 14/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7349\n",
      "Epoch 15/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7352\n",
      "Epoch 16/150\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7360\n",
      "Epoch 17/150\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5459 - accuracy: 0.7353: 0s - - ETA: 0s - loss: 0.5431 - ac - ETA: \n",
      "Epoch 18/150\n",
      "858/858 [==============================] - 3s 3ms/step - loss: 0.5455 - accuracy: 0.7357\n",
      "Epoch 19/150\n",
      "858/858 [==============================] - 3s 4ms/step - loss: 0.5447 - accuracy: 0.7360\n",
      "Epoch 20/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7366\n",
      "Epoch 21/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7363\n",
      "Epoch 22/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7364\n",
      "Epoch 23/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7376\n",
      "Epoch 24/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7369: 0s - loss: 0.5456 - accura - ETA: 0s - loss: 0.5456 - accuracy: 0.73 - ETA: 0s - loss: 0.5455 - ac\n",
      "Epoch 25/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7367\n",
      "Epoch 26/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7364\n",
      "Epoch 27/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7373\n",
      "Epoch 28/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7376\n",
      "Epoch 29/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5426 - accuracy: 0.7369\n",
      "Epoch 30/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7374\n",
      "Epoch 31/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7375\n",
      "Epoch 32/150\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7378\n",
      "Epoch 33/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7379\n",
      "Epoch 34/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7380\n",
      "Epoch 35/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7377\n",
      "Epoch 36/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7379\n",
      "Epoch 37/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7382\n",
      "Epoch 38/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5412 - accuracy: 0.7375\n",
      "Epoch 39/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7383\n",
      "Epoch 40/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5414 - accuracy: 0.7378: \n",
      "Epoch 41/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7379\n",
      "Epoch 42/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5414 - accuracy: 0.7381\n",
      "Epoch 43/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5410 - accuracy: 0.7391\n",
      "Epoch 44/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.7391\n",
      "Epoch 45/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5405 - accuracy: 0.7379\n",
      "Epoch 46/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5403 - accuracy: 0.7381\n",
      "Epoch 47/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7380\n",
      "Epoch 48/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7386\n",
      "Epoch 49/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5396 - accuracy: 0.7386\n",
      "Epoch 50/150\n",
      "858/858 [==============================] - 1s 941us/step - loss: 0.5402 - accuracy: 0.7389\n",
      "Epoch 51/150\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5396 - accuracy: 0.7385\n",
      "Epoch 52/150\n",
      "858/858 [==============================] - 1s 921us/step - loss: 0.5396 - accuracy: 0.7388\n",
      "Epoch 53/150\n",
      "858/858 [==============================] - 1s 888us/step - loss: 0.5398 - accuracy: 0.7389\n",
      "Epoch 54/150\n",
      "858/858 [==============================] - 1s 905us/step - loss: 0.5394 - accuracy: 0.7391\n",
      "Epoch 55/150\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5394 - accuracy: 0.7389\n",
      "Epoch 56/150\n",
      "858/858 [==============================] - 1s 970us/step - loss: 0.5393 - accuracy: 0.7385\n",
      "Epoch 57/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5396 - accuracy: 0.7385: 0s - loss: 0.542\n",
      "Epoch 58/150\n",
      "858/858 [==============================] - 1s 963us/step - loss: 0.5391 - accuracy: 0.7395\n",
      "Epoch 59/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.7383\n",
      "Epoch 60/150\n",
      "858/858 [==============================] - 1s 979us/step - loss: 0.5392 - accuracy: 0.7389\n",
      "Epoch 61/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5390 - accuracy: 0.7392: 0s - l\n",
      "Epoch 62/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7386\n",
      "Epoch 63/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7385\n",
      "Epoch 64/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.7395\n",
      "Epoch 65/150\n",
      "858/858 [==============================] - 1s 961us/step - loss: 0.5391 - accuracy: 0.7392\n",
      "Epoch 66/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7393\n",
      "Epoch 67/150\n",
      "858/858 [==============================] - 1s 999us/step - loss: 0.5388 - accuracy: 0.7387\n",
      "Epoch 68/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7391\n",
      "Epoch 69/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7391\n",
      "Epoch 70/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.7391\n",
      "Epoch 71/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7392\n",
      "Epoch 72/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.7385\n",
      "Epoch 73/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7388\n",
      "Epoch 74/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5379 - accuracy: 0.7390\n",
      "Epoch 75/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.7392\n",
      "Epoch 76/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.7397\n",
      "Epoch 77/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7400\n",
      "Epoch 78/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7387\n",
      "Epoch 79/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7390\n",
      "Epoch 80/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7396\n",
      "Epoch 81/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7401\n",
      "Epoch 82/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7395\n",
      "Epoch 83/150\n",
      "858/858 [==============================] - 1s 948us/step - loss: 0.5377 - accuracy: 0.7393\n",
      "Epoch 84/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.7399\n",
      "Epoch 85/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7405\n",
      "Epoch 86/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7406\n",
      "Epoch 87/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7390\n",
      "Epoch 88/150\n",
      "858/858 [==============================] - 1s 972us/step - loss: 0.5376 - accuracy: 0.7395\n",
      "Epoch 89/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7397\n",
      "Epoch 90/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7397\n",
      "Epoch 91/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7400\n",
      "Epoch 92/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7398\n",
      "Epoch 93/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5371 - accuracy: 0.7396\n",
      "Epoch 94/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5371 - accuracy: 0.7396\n",
      "Epoch 95/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7393\n",
      "Epoch 96/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7396\n",
      "Epoch 97/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5371 - accuracy: 0.7400\n",
      "Epoch 98/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7409\n",
      "Epoch 99/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7399\n",
      "Epoch 100/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7394\n",
      "Epoch 101/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7403\n",
      "Epoch 102/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7398\n",
      "Epoch 103/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7405\n",
      "Epoch 104/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7401\n",
      "Epoch 105/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7401\n",
      "Epoch 106/150\n",
      "858/858 [==============================] - 1s 886us/step - loss: 0.5364 - accuracy: 0.7403\n",
      "Epoch 107/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7405\n",
      "Epoch 108/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7404\n",
      "Epoch 109/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7399\n",
      "Epoch 110/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7403\n",
      "Epoch 111/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7400\n",
      "Epoch 112/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7403\n",
      "Epoch 113/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7405\n",
      "Epoch 114/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7400\n",
      "Epoch 115/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7403\n",
      "Epoch 116/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7406\n",
      "Epoch 117/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7406\n",
      "Epoch 118/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7401\n",
      "Epoch 119/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7401\n",
      "Epoch 120/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7401\n",
      "Epoch 121/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7404\n",
      "Epoch 122/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7403\n",
      "Epoch 123/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7403\n",
      "Epoch 124/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7405\n",
      "Epoch 125/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7404\n",
      "Epoch 126/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7407\n",
      "Epoch 127/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7410\n",
      "Epoch 128/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7410\n",
      "Epoch 129/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7403\n",
      "Epoch 130/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7401\n",
      "Epoch 131/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7404: 0s - loss: 0.530\n",
      "Epoch 132/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7406\n",
      "Epoch 133/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7405\n",
      "Epoch 134/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7406: 0s - loss: 0.5364 - ac\n",
      "Epoch 135/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7404\n",
      "Epoch 136/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7408\n",
      "Epoch 137/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7396\n",
      "Epoch 138/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7407\n",
      "Epoch 139/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7401\n",
      "Epoch 140/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7406\n",
      "Epoch 141/150\n",
      "858/858 [==============================] - 2s 3ms/step - loss: 0.5356 - accuracy: 0.7409\n",
      "Epoch 142/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7409\n",
      "Epoch 143/150\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7408\n",
      "Epoch 144/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7404\n",
      "Epoch 145/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7405\n",
      "Epoch 146/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7404\n",
      "Epoch 147/150\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7407\n",
      "Epoch 148/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7405\n",
      "Epoch 149/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7408\n",
      "Epoch 150/150\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7402\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model_fit = nn.fit(X_train_scaled, y_train, epochs=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 0s - loss: 0.5911 - accuracy: 0.7280 - 257ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#  evaluate the model\n",
    "model_loss, model_acc = nn.evaluate(X_test_scaled, y_test,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to HDF5 file\n",
    "nn.save('AlphabetSoupCharity_optimization.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "696a868d263820d96c3e015462b3285736058cba07fad26566882fe661452fde"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
